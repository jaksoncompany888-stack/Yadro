"""
Yadro v0 - Step Executor

Executes individual steps in the plan.
"""
from typing import Any, Optional, Callable, Dict
from datetime import datetime, timezone

from .models import Step, StepAction, StepStatus, ExecutionContext
from ..kernel import TaskManager, PauseReason
from ..tools.registry import registry as tool_registry


class ApprovalRequired(Exception):
    """Raised when step requires user approval."""

    def __init__(self, message: str, step_id: str, draft_content: Optional[str] = None):
        super().__init__(message)
        self.step_id = step_id
        self.draft_content = draft_content


def _markdown_to_html(text: str) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è markdown –≤ HTML –¥–ª—è Telegram. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ."""
    import re

    # –£–±–∏—Ä–∞–µ–º markdown –∑–∞–≥–æ–ª–æ–≤–∫–∏ (### –ò–¥–µ—è ‚Üí –ò–¥–µ—è)
    # LLM —á–∞—Å—Ç–æ –æ—Ç–≤–µ—á–∞–µ—Ç —Å ### –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã ‚Äî —É–±–∏—Ä–∞–µ–º —Ä–µ—à—ë—Ç–∫–∏
    text = re.sub(r'^#{1,6}\s*', '', text, flags=re.MULTILINE)

    # –ü–æ—Ä—è–¥–æ–∫ –≤–∞–∂–µ–Ω! –°–Ω–∞—á–∞–ª–∞ –¥–≤–æ–π–Ω—ã–µ, –ø–æ—Ç–æ–º –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ
    # __bold__ ‚Üí <b>bold</b>
    text = re.sub(r'__([^_]+?)__', r'<b>\1</b>', text)
    # **bold** ‚Üí <b>bold</b>
    text = re.sub(r'\*\*([^\*]+?)\*\*', r'<b>\1</b>', text)
    # _italic_ ‚Üí <i>italic</i> (–Ω–æ –Ω–µ –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ–≤ —Ç–∏–ø–∞ snake_case)
    text = re.sub(r'(?<!\w)_([^_]+?)_(?!\w)', r'<i>\1</i>', text)
    # *italic* ‚Üí <i>italic</i>
    text = re.sub(r'(?<!\w)\*([^\*]+?)\*(?!\w)', r'<i>\1</i>', text)

    # –û—á–∏—Å—Ç–∫–∞ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö/–¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–≥–æ–≤
    # <b><b>text</b></b> ‚Üí <b>text</b>
    while '<b><b>' in text:
        text = text.replace('<b><b>', '<b>')
    while '</b></b>' in text:
        text = text.replace('</b></b>', '</b>')
    while '<i><i>' in text:
        text = text.replace('<i><i>', '<i>')
    while '</i></i>' in text:
        text = text.replace('</i></i>', '</i>')

    return text


def _apply_style_postprocess(text: str, smm_context: str) -> str:
    """
    –ü–æ—Å—Ç-–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä: –ø—Ä–∏–º–µ–Ω—è–µ—Ç —Å—Ç–∏–ª—å –∫–∞–Ω–∞–ª–∞ –∫ –ø–æ—Å—Ç—É (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ).

    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç smm_context, –∏–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å—Ç–∏–ª—è, –ø—Ä–∏–º–µ–Ω—è–µ—Ç –∫ –ø–æ—Å—Ç—É.
    """
    import re

    if not smm_context:
        print(f"[PostProcess] –ù–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
        return text

    context_lower = smm_context.lower()

    # === 1. –≠–ú–û–î–ó–ò ===
    emoji_pattern = re.compile("[\U0001F300-\U0001F9FF\u2600-\u26FF\u2700-\u27BF\u2300-\u23FF]+")

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–º–æ–¥–∑–∏ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–ø—Ä–∏–º–µ—Ä—ã –ø–æ—Å—Ç–æ–≤, —Å—Ç–∏–ª–∏ –∫–∞–Ω–∞–ª–æ–≤)
    context_emojis = emoji_pattern.findall(smm_context)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–ø—Ä–µ—Ç –Ω–∞ —ç–º–æ–¥–∑–∏
    anti_emoji = ['–±–µ–∑ —ç–º–æ–¥–∑–∏', '–º–∞–ª–æ —ç–º–æ–¥–∑–∏', '—Ä–µ–¥–∫–æ —ç–º–æ–¥–∑–∏', '0 –Ω–∞ –ø–æ—Å—Ç', '–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —ç–º–æ–¥–∑–∏']
    emoji_forbidden = any(k in context_lower for k in anti_emoji)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —ç–º–æ–¥–∑–∏ –≤ –ø–æ—Å—Ç–µ
    has_emoji = bool(emoji_pattern.search(text))

    # –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å —ç–º–æ–¥–∑–∏ –ò –≤ –ø–æ—Å—Ç–µ –∏—Ö –Ω–µ—Ç ‚Üí –¥–æ–±–∞–≤–ª—è–µ–º
    if context_emojis and not emoji_forbidden and not has_emoji:
        emoji_set = list(set(context_emojis))[:5]
        text = f"{emoji_set[0]} " + text
        if len(emoji_set) > 1:
            text = text + f" {emoji_set[1]}"
        print(f"[PostProcess] –î–æ–±–∞–≤–ª–µ–Ω—ã —ç–º–æ–¥–∑–∏ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {emoji_set[:3]}")

    # === 2. –ñ–ò–†–ù–´–ô –¢–ï–ö–°–¢ ===
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –∂–∏—Ä–Ω—ã–π –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ (–ø—Ä–∏–º–µ—Ä—ã –ø–æ—Å—Ç–æ–≤)
    has_bold_in_context = '<b>' in smm_context or '**' in smm_context
    has_bold = '<b>' in text

    if has_bold_in_context and not has_bold:
        # –í—ã–¥–µ–ª—è–µ–º –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∂–∏—Ä–Ω—ã–º
        sentences = re.split(r'(?<=[.!?])\s+', text, maxsplit=1)
        if sentences:
            text = f"<b>{sentences[0]}</b>"
            if len(sentences) > 1:
                text += "\n\n" + sentences[1]
        print(f"[PostProcess] –î–æ–±–∞–≤–ª–µ–Ω –∂–∏—Ä–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫")

    return text


class StepExecutor:
    """
    Executes individual steps.

    Routes step actions to appropriate handlers:
    - LLM_CALL ‚Üí LLM Service
    - TOOL_CALL ‚Üí Tool Runtime
    - APPROVAL ‚Üí Pause for user
    - CONDITION ‚Üí Evaluate and decide
    - AGGREGATE ‚Üí Combine results
    """

    def __init__(self, task_manager: Optional[TaskManager] = None, llm_service=None):
        """
        Initialize StepExecutor.

        Args:
            task_manager: TaskManager for pausing tasks
            llm_service: LLMService for LLM calls
        """
        self._task_manager = task_manager
        self._llm_service = llm_service

        # Handler registry
        self._handlers: Dict[StepAction, Callable] = {
            StepAction.LLM_CALL: self._handle_llm_call,
            StepAction.TOOL_CALL: self._handle_tool_call,
            StepAction.APPROVAL: self._handle_approval,
            StepAction.CONDITION: self._handle_condition,
            StepAction.AGGREGATE: self._handle_aggregate,
        }

    @property
    def task_manager(self) -> TaskManager:
        """Get task manager (lazy init)."""
        if self._task_manager is None:
            self._task_manager = TaskManager()
        return self._task_manager

    def execute(self, step: Step, context: ExecutionContext) -> Any:
        """
        Execute a single step.

        Args:
            step: Step to execute
            context: Execution context

        Returns:
            Step result

        Raises:
            ApprovalRequired: If step needs user approval
            Exception: If step execution fails
        """
        handler = self._handlers.get(step.action)
        if handler is None:
            raise ValueError(f"Unknown step action: {step.action}")

        # Mark step as running
        step.status = StepStatus.RUNNING
        step.started_at = datetime.now(timezone.utc)

        try:
            result = handler(step, context)

            # Mark success
            step.status = StepStatus.COMPLETED
            step.result = result
            step.completed_at = datetime.now(timezone.utc)

            # Store in context
            context.add_step_result(step.step_id, result)
            context.steps_executed += 1

            return result

        except ApprovalRequired:
            # Step paused for approval - reset to pending
            step.status = StepStatus.PENDING
            step.started_at = None
            raise

        except Exception as e:
            step.status = StepStatus.FAILED
            step.error = str(e)
            step.completed_at = datetime.now(timezone.utc)
            raise

    # ==================== HANDLERS ====================

    def _handle_llm_call(self, step: Step, context: ExecutionContext) -> Any:
        """
        Handle LLM call step.

        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–π LLM Service –∏ SMM-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã.
        """
        purpose = step.action_data.get("purpose", "general")
        input_text = step.action_data.get("input_text") or context.input_text
        system_prompt = step.action_data.get("system_prompt", "")
        prompt_template = step.action_data.get("prompt", "")
        smm_context = step.action_data.get("smm_context", "")

        # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —à–∞–≥–æ–≤
        prev_results = []
        for dep_id in step.depends_on:
            dep_result = context.get_step_result(dep_id)
            if dep_result:
                prev_results.append(dep_result)

        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π LLM ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        if self._llm_service is not None:
            try:
                from ..llm import Message

                # –ü–æ–ª—É—á–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏ user prompt –¥–ª—è SMM
                if purpose.startswith("smm_"):
                    sys_prompt, user_prompt = self._build_smm_prompt(
                        purpose, input_text, prev_results, smm_context, step.action_data
                    )
                elif prompt_template:
                    sys_prompt = system_prompt or self._get_system_prompt(purpose)
                    user_prompt = prompt_template.format(
                        input=input_text or "",
                        context=prev_results,
                        **step.action_data
                    )
                else:
                    sys_prompt = system_prompt or self._get_system_prompt(purpose)
                    user_prompt = self._build_prompt(purpose, input_text, prev_results, step.action_data)

                print(f"[Step] LLM_CALL: {purpose}")

                response = self._llm_service.complete(
                    messages=[
                        Message.system(sys_prompt),
                        Message.user(user_prompt)
                    ],
                    user_id=context.user_id,
                    task_id=context.task_id
                )

                print(f"[Step] LLM_CALL: {purpose} ‚Üí OK ({response.total_tokens} tokens)")

                # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è SMM –ø–æ—Å—Ç–æ–≤ (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ)
                content = response.content
                if purpose.startswith("smm_generate"):
                    content = _markdown_to_html(content)
                    content = _apply_style_postprocess(content, smm_context)

                return {
                    "purpose": purpose,
                    "response": content,
                    "model": response.model,
                    "tokens_used": response.total_tokens,
                }

            except Exception as e:
                print(f"[Step] LLM_CALL: {purpose} ‚Üí ERROR: {e}")
                return {"purpose": purpose, "error": str(e)}

        # Fallback: mock
        print(f"[Step] LLM_CALL: {purpose} ‚Üí MOCK (no llm_service)")
        mock_responses = {
            "analyze": f"Analysis of: {input_text[:50] if input_text else 'N/A'}...",
            "research": f"Research findings for: {input_text[:50] if input_text else 'N/A'}",
            "smm_generate_post": f"–ü–æ—Å—Ç –ø—Ä–æ {input_text}:\n\n–≠—Ç–æ —Ç–µ—Å—Ç–æ–≤—ã–π –ø–æ—Å—Ç. #—Ç–µ—Å—Ç",
            "smm_analyze_style": "–°—Ç–∏–ª—å: –¥–µ—Ä–∑–∫–∏–π, –∫–æ—Ä–æ—Ç–∫–∏–µ –ø–æ—Å—Ç—ã, –º–Ω–æ–≥–æ —ç–º–æ–¥–∑–∏",
            "summarize": f"Summary: {input_text[:100] if input_text else 'N/A'}...",
        }

        return {
            "purpose": purpose,
            "response": mock_responses.get(purpose, f"Mock response for {purpose}"),
            "model": "mock",
            "tokens_used": 0,
        }

    def _build_smm_prompt(
        self,
        purpose: str,
        input_text: str,
        prev_results: list,
        smm_context: str,
        action_data: dict
    ) -> tuple:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è SMM –∑–∞–¥–∞—á. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (system_prompt, user_prompt)."""

        if purpose == "smm_generate_post":
            system_prompt = """–¢—ã –æ–ø—ã—Ç–Ω—ã–π SMM-–∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä. –ü–∏—à–µ—à—å —Ç–∞–∫, —á—Ç–æ–±—ã –ù–ò–ö–¢–û –Ω–µ –∑–∞–ø–æ–¥–æ–∑—Ä–∏–ª AI.

–ì–õ–ê–í–ù–û–ï –ü–†–ê–í–ò–õ–û: –ü–∏—à–∏ –∫–∞–∫ –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫ –∫–æ—Ç–æ—Ä—ã–π —Ä–µ–∞–ª—å–Ω–æ —Ä–∞–∑–±–∏—Ä–∞–µ—Ç—Å—è –≤ —Ç–µ–º–µ.

–ö–ê–¢–ï–ì–û–†–ò–ß–ï–°–ö–ò –ó–ê–ü–†–ï–©–ï–ù–û (–¥–µ—Ç–µ–∫—Ç–∏—Ç—Å—è –∫–∞–∫ AI):
- "–∑–Ω–∞–º–µ–Ω—É–µ—Ç –Ω–æ–≤—É—é —ç—Ä—É", "—è–≤–ª—è–µ—Ç—Å—è —Å–≤–∏–¥–µ—Ç–µ–ª—å—Å—Ç–≤–æ–º", "—Å–ª—É–∂–∏—Ç –ø—Ä–∏–º–µ—Ä–æ–º"
- "–∏–≥—Ä–∞–µ—Ç –≤–∞–∂–Ω—É—é/–∫–ª—é—á–µ–≤—É—é —Ä–æ–ª—å", "–∏–º–µ–µ—Ç –æ–≥—Ä–æ–º–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"
- "–Ω–µ –ø—Ä–æ—Å—Ç–æ X, —ç—Ç–æ Y" ‚Äî –ù–ò–ö–û–ì–î–ê —Ç–∞–∫ –Ω–µ –ø–∏—à–∏
- "–≤–∞–∂–Ω–æ –æ—Ç–º–µ—Ç–∏—Ç—å", "—Å—Ç–æ–∏—Ç –æ—Ç–º–µ—Ç–∏—Ç—å", "—Å–ª–µ–¥—É–µ—Ç –ø–æ–¥—á–µ—Ä–∫–Ω—É—Ç—å"
- "–≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–º –º–∏—Ä–µ", "–≤ –Ω–∞—à–µ –≤—Ä–µ–º—è", "–≤ —ç–ø–æ—Ö—É"
- "—ç–∫—Å–ø–µ—Ä—Ç—ã –æ—Ç–º–µ—á–∞—é—Ç/—Å—á–∏—Ç–∞—é—Ç/–ø–æ–ª–∞–≥–∞—é—Ç" –±–µ–∑ –ö–û–ù–ö–†–ï–¢–ù–´–• –∏–º—ë–Ω
- –î–µ–µ–ø—Ä–∏—á–∞—Å—Ç–∏—è –≤ –∫–æ–Ω—Ü–µ: "–ø–æ–¥—á—ë—Ä–∫–∏–≤–∞—è...", "–æ—Ç—Ä–∞–∂–∞—è...", "–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—è..."
- –°–ø–∏—Å–∫–∏ —Ä–æ–≤–Ω–æ –∏–∑ 3 –ø—É–Ω–∫—Ç–æ–≤
- –û–¥–Ω–∞ –º—ã—Å–ª—å —Ä–∞–∑–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏: "–±–æ–ª—å—à–æ–π, –æ–≥—Ä–æ–º–Ω—ã–π, –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π"
- "–±–æ–ª–µ–µ —Ç–æ–≥–æ", "–∫—Ä–æ–º–µ —Ç–æ–≥–æ", "–ø–æ–º–∏–º–æ —ç—Ç–æ–≥–æ" ‚Äî –∫–∞–Ω—Ü–µ–ª—è—Ä–∏—Ç
- –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω—ã–µ —Å—Ç–µ–ø–µ–Ω–∏ –±–µ–∑ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤: "–ª—É—á—à–∏–π", "—É–Ω–∏–∫–∞–ª—å–Ω—ã–π", "—Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–π"

–ö–ê–ö –ü–ò–®–£–¢ –ñ–ò–í–´–ï –õ–Æ–î–ò:
- –ì–æ–≤–æ—Ä–∏—à—å "—è –¥—É–º–∞—é", "–ø–æ –º–æ–µ–º—É –æ–ø—ã—Ç—É", "–º—ã –∑–∞–º–µ—Ç–∏–ª–∏"
- –ö–æ–Ω–∫—Ä–µ—Ç–∏–∫–∞: "47% –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π", –∞ –Ω–µ "–º–Ω–æ–≥–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏"
- –ú–æ–∂–µ—à—å —Å–æ–º–Ω–µ–≤–∞—Ç—å—Å—è: "–Ω–µ —É–≤–µ—Ä–µ–Ω, –Ω–æ...", "–≤–æ–∑–º–æ–∂–Ω–æ..."
- –®—É—Ç–∏—à—å, –∏—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—à—å –≥–¥–µ —É–º–µ—Å—Ç–Ω–æ
- –ó–∞–¥–∞—ë—à—å –≤–æ–ø—Ä–æ—Å—ã —á–∏—Ç–∞—Ç–µ–ª—é
- –ö–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –∫–∞–∫ –≤ —Ä–∞–∑–≥–æ–≤–æ—Ä–µ
- –ï—Å–ª–∏ –≤ –ø—Ä–∏–º–µ—Ä–∞—Ö –ø–æ—Å—Ç–æ–≤ –µ—Å—Ç—å AI-–ø–∞—Ç—Ç–µ—Ä–Ω—ã ‚Äî –ù–ï –ö–û–ü–ò–†–£–ô –∏—Ö, –ø–∏—à–∏ –ª—É—á—à–µ"""

            # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —à–∞–≥–æ–≤
            similar_posts = ""
            web_info = ""

            for res in prev_results:
                if isinstance(res, dict):
                    if res.get("tool") == "memory_search":
                        results = res.get("results", [])
                        if results:
                            similar_posts = "\n".join([
                                f"‚Ä¢ {r.get('content', '')[:200]}"
                                for r in results[:3]
                            ])
                    elif res.get("tool") == "web_search":
                        results = res.get("results", [])
                        if results:
                            web_info = "\n".join([
                                f"‚Ä¢ {r.get('title', '')}: {r.get('summary', '')[:150]}"
                                for r in results[:3]
                            ])

            # –°–æ–±–∏—Ä–∞–µ–º user prompt
            parts = []

            if smm_context:
                parts.append(smm_context)

            if similar_posts:
                parts.append(f"–ü–û–•–û–ñ–ò–ï –ü–û–°–¢–´ (–≤–¥–æ—Ö–Ω–æ–≤–ª—è–π—Å—è):\n{similar_posts}")

            if web_info:
                parts.append(f"–ê–ö–¢–£–ê–õ–¨–ù–ê–Ø –ò–ù–§–ê:\n{web_info}")

            context_text = "\n\n".join(parts)

            user_prompt = f"""–ù–∞–ø–∏—à–∏ –ø–æ—Å—Ç –¥–ª—è Telegram-–∫–∞–Ω–∞–ª–∞.

{context_text}

–¢–ï–ú–ê: {input_text}

–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û:
1. –ö–æ–ø–∏—Ä—É–π –°–¢–ò–õ–¨ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞–Ω–∞–ª–æ–≤ ‚Äî –¥–ª–∏–Ω–∞, —Ç–æ–Ω, —Ñ–æ—Ä–º–∞—Ç, —ç–º–æ–¥–∑–∏
2. –ï—Å–ª–∏ –≤ —Å—Ç–∏–ª–µ –µ—Å—Ç—å —ç–º–æ–¥–∑–∏ ‚Äî –ò–°–ü–û–õ–¨–ó–£–ô —ç–º–æ–¥–∑–∏ (üî• üí° ‚ú® –∏ —Ç.–¥.)
3. –£—á–∏—Ç—ã–≤–∞–π –ü–†–ê–í–ö–ò –ö–õ–ò–ï–ù–¢–ê ‚Äî —ç—Ç–æ –µ–≥–æ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
4. –í–¥–æ—Ö–Ω–æ–≤–ª—è–π—Å—è –ü–†–ò–ú–ï–†–ê–ú–ò –∫–æ—Ç–æ—Ä—ã–µ –∑–∞—à–ª–∏

–ù–∞–ø–∏—à–∏ —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞."""

            return system_prompt, user_prompt

        elif purpose == "smm_analyze_style":
            system_prompt = "–¢—ã –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä-–∞–Ω–∞–ª–∏—Ç–∏–∫. –†–∞–∑–±–∏—Ä–∞–µ—à—å —Å—Ç–∏–ª—å –ø–æ—Å—Ç–æ–≤ –¥–ª—è –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä–∞."

            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å—Ç—ã –∏–∑ parse_channel
            posts_text = ""
            channel = input_text

            for res in prev_results:
                if isinstance(res, dict) and res.get("tool") == "parse_channel":
                    posts = res.get("posts", [])
                    if posts:
                        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∫–ª–∞–º—É
                        organic = [p for p in posts if not self._is_ad_post(p.get("text", ""))][:5]
                        posts_text = "\n".join([
                            f"[{p.get('views', 0)} views] {p.get('text', '')[:200]}"
                            for p in organic
                        ])

            user_prompt = f"""–†–∞–∑–±–µ—Ä–∏ —Å—Ç–∏–ª—å –∫–∞–Ω–∞–ª–∞ {channel} –¥–ª—è –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä–∞.

–ü–û–°–¢–´:
{posts_text}

–î–∞–π –ö–û–ù–ö–†–ï–¢–ò–ö–£:
1. HOOKS ‚Äî –∫–∞–∫ —Ü–µ–ø–ª—è—é—Ç –≤–Ω–∏–º–∞–Ω–∏–µ? –ü—Ä–∏–º–µ—Ä—ã —Ñ—Ä–∞–∑.
2. –°–¢–†–£–ö–¢–£–†–ê ‚Äî –∫–∞–∫ —Å—Ç—Ä–æ—è—Ç –ø–æ—Å—Ç?
3. –§–ò–®–ö–ò ‚Äî —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –ø—Ä–∏—ë–º—ã, —Å–ª–æ–≤–∞.
4. –ö–û–ù–¶–û–í–ö–ê ‚Äî CTA?
5. –î–õ–ò–ù–ê ‚Äî —Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤?

–ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ, —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏."""

            return system_prompt, user_prompt

        elif purpose == "smm_deep_analyze":
            # –ì–õ–£–ë–û–ö–ò–ô –ê–ù–ê–õ–ò–ó ‚Äî –ø–æ–ª—É—á–∞–µ–º –≥–æ—Ç–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —à–∞–≥–æ–≤
            system_prompt = "–¢—ã –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä-–∞–Ω–∞–ª–∏—Ç–∏–∫. –î–µ–ª–∞–µ—à—å –≥–ª—É–±–æ–∫–∏–π —Ä–∞–∑–±–æ—Ä —Å—Ç–∏–ª—è –∫–∞–Ω–∞–ª–∞ –¥–ª—è –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä–∞."

            channel = input_text
            posts_data = None
            metrics_data = None

            for res in prev_results:
                if isinstance(res, dict):
                    if res.get("tool") == "parse_channel":
                        posts_data = res
                    elif res.get("tool") == "compute_channel_metrics":
                        metrics_data = res.get("metrics", {})

            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –º–µ—Ç—Ä–∏–∫
            metrics_text = ""
            if metrics_data:
                metrics_text = f"""
–ú–ï–¢–†–ò–ö–ò (–≤—ã—á–∏—Å–ª–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏):
- –î–ª–∏–Ω–∞ –ø–æ—Å—Ç–æ–≤: {metrics_data.get('length_category', '?')} (–≤ —Å—Ä–µ–¥–Ω–µ–º {metrics_data.get('avg_length', 0)} —Å–∏–º–≤–æ–ª–æ–≤)
- –≠–º–æ–¥–∑–∏: {metrics_data.get('emoji_style', '?')} ({metrics_data.get('avg_emoji', 0)} –Ω–∞ –ø–æ—Å—Ç)
- –•–µ—à—Ç–µ–≥–∏: {metrics_data.get('avg_hashtags', 0)} –Ω–∞ –ø–æ—Å—Ç, —Ç–æ–ø: {', '.join(metrics_data.get('top_hashtags', [])[:3])}
- –°—Ç—Ä—É–∫—Ç—É—Ä–∞: {', '.join(metrics_data.get('structure', []))}
- –•—É–∫–∏: {', '.join(metrics_data.get('hook_patterns', []))}
- –ö–æ–Ω—Ü–æ–≤–∫–∏: {metrics_data.get('cta_style', '?')}
- –¢–æ–ø —Å–ª–æ–≤–∞: {', '.join(metrics_data.get('top_words', [])[:7])}
- –ü—Ä–æ—Å–º–æ—Ç—Ä—ã: ~{metrics_data.get('avg_views', 0)}"""

            # –ü—Ä–∏–º–µ—Ä—ã —Ö—É–∫–æ–≤ –∏ –∫–æ–Ω—Ü–æ–≤–æ–∫
            examples = metrics_data.get("examples", {}) if isinstance(metrics_data, dict) else {}
            examples_text = ""
            if examples:
                hooks = examples.get("hooks", [])
                endings = examples.get("endings", [])
                if hooks:
                    examples_text += f"\n\n–ü–†–ò–ú–ï–†–´ –•–£–ö–û–í:\n" + "\n".join([f"‚Ä¢ {h[:60]}..." for h in hooks[:3]])
                if endings:
                    examples_text += f"\n\n–ü–†–ò–ú–ï–†–´ –ö–û–ù–¶–û–í–û–ö:\n" + "\n".join([f"‚Ä¢ {e[:60]}..." for e in endings[:3]])

            # –ù–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Å—Ç–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            posts_text = ""
            if posts_data and posts_data.get("posts"):
                posts = posts_data.get("posts", [])[:3]
                posts_text = "\n\n–õ–£–ß–®–ò–ï –ü–û–°–¢–´:\n" + "\n---\n".join([
                    f"[{p.get('views', 0)} views] {p.get('text', '')[:300]}..."
                    for p in posts
                ])

            user_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–∞–Ω–∞–ª {channel} –¥–ª—è –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä–∞.
{metrics_text}
{examples_text}
{posts_text}

–ó–ê–î–ê–ß–ê: –ù–∞ –æ—Å–Ω–æ–≤–µ –ú–ï–¢–†–ò–ö –∏ –ü–†–ò–ú–ï–†–û–í –≤—ã–¥–µ–ª–∏:

1. TONE OF VOICE ‚Äî –∫–∞–∫ –±—Ä–µ–Ω–¥ —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞–µ—Ç? (—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π/–¥–µ—Ä–∑–∫–∏–π/–¥—Ä—É–∂–µ—Å–∫–∏–π –∏ —Ç.–¥.)
2. –§–û–†–ú–£–õ–ê –ü–û–°–¢–ê ‚Äî —Ç–∏–ø–∏—á–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: hook ‚Üí body ‚Üí CTA
3. –§–ò–†–ú–ï–ù–ù–´–ï –ü–†–ò–Å–ú–´ ‚Äî —á—Ç–æ –æ—Ç–ª–∏—á–∞–µ—Ç —ç—Ç–æ—Ç –∫–∞–Ω–∞–ª?
4. –¢–†–ò–ì–ì–ï–†–´ –í–û–í–õ–ï–ß–ï–ù–ò–Ø ‚Äî –ø–æ—á–µ–º—É —á–∏—Ç–∞—é—Ç –∏ —Ä–µ–∞–≥–∏—Ä—É—é—Ç?
5. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò ‚Äî –∫–∞–∫ –ø–∏—Å–∞—Ç—å –≤ —ç—Ç–æ–º —Å—Ç–∏–ª–µ?

–ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ, —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ —Ñ—Ä–∞–∑."""

            return system_prompt, user_prompt

        elif purpose == "smm_generate_edit_content":
            # –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–û–ù–¢–ï–ù–¢–ê –î–õ–Ø –†–ï–î–ê–ö–¢–ò–†–û–í–ê–ù–ò–Ø
            # LLM –≥–µ–Ω–µ—Ä–∏—Ç –¢–û–õ–¨–ö–û –Ω—É–∂–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (—Ö—É–∫, –∞–±–∑–∞—Ü), –ù–ï –≤–∏–¥–∏—Ç –≤–µ—Å—å –ø–æ—Å—Ç
            system_prompt = """–¢—ã SMM-–∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—à—å –¢–û–õ–¨–ö–û –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç.

–ù–ï –ø–∏—à–∏ –≤–µ—Å—å –ø–æ—Å—Ç ‚Äî —Ç–æ–ª—å–∫–æ —Ç–æ —á—Ç–æ –ø—Ä–æ—Å—è—Ç: —Ö—É–∫, –∞–±–∑–∞—Ü, —Ö—ç—à—Ç–µ–≥–∏.
–£—á–∏—Ç—ã–≤–∞–π —Å—Ç–∏–ª—å –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."""

            topic = action_data.get("topic", "")

            # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —à–∞–≥–æ–≤
            style_context = ""
            web_context = ""
            operations = []

            for res in prev_results:
                if isinstance(res, dict):
                    # –ò–Ω—Ç–µ–Ω—Ç —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                    if res.get("tool") == "parse_edit_intent":
                        operations = res.get("operations", [])
                    # –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–∞–º—è—Ç–∏
                    elif res.get("tool") == "memory_search":
                        results = res.get("results", [])
                        if results:
                            style_context = "\n".join([r.get("content", "")[:200] for r in results[:3]])
                    # Web search
                    elif res.get("tool") == "web_search":
                        results = res.get("results", [])
                        if results:
                            web_context = "\n".join([f"‚Ä¢ {r.get('title', '')}: {r.get('snippet', '')[:100]}" for r in results[:3]])

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —á—Ç–æ –Ω—É–∂–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å
            needs = []
            for op in operations:
                if op.get("needs_generation"):
                    op_type = op.get("type", "")
                    if op_type == "add_hook":
                        needs.append(f"HOOK: —Ü–µ–ø–ª—è—é—â–µ–µ –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø—Ä–æ '{topic}'. 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, —Å —ç–º–æ–¥–∑–∏.")
                    elif op_type == "add_paragraph":
                        context = op.get("context", "")
                        needs.append(f"PARAGRAPH: –∞–±–∑–∞—Ü –Ω–∞ —Ç–µ–º—É '{context}'. 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.")
                    elif op_type == "add_hashtags":
                        needs.append(f"HASHTAGS: 3-5 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ö—ç—à—Ç–µ–≥–æ–≤ –¥–ª—è –ø–æ—Å—Ç–∞ –ø—Ä–æ '{topic}'")
                    elif op_type == "shorten":
                        needs.append("SHORTEN: —É–∫–∞–∂–∏ –∫–∞–∫–∏–µ —á–∞—Å—Ç–∏ –º–æ–∂–Ω–æ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å")
                    elif op_type == "expand":
                        needs.append(f"EXPAND: –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –ø—Ä–æ '{topic}'. 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.")

            if not needs:
                return system_prompt, "–ù–∏—á–µ–≥–æ –Ω–µ –Ω—É–∂–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å."

            user_prompt = f"""–¢–ï–ú–ê –ü–û–°–¢–ê: {topic}

–°–¢–ò–õ–¨ (–∏–∑ —É—Å–ø–µ—à–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤):
{style_context if style_context else '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'}

–ê–ö–¢–£–ê–õ–¨–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:
{web_context if web_context else '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'}

–ù–£–ñ–ù–û –°–ì–ï–ù–ï–†–ò–†–û–í–ê–¢–¨:
{chr(10).join(needs)}

–û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
{{
  "hook": "—Ç–µ–∫—Å—Ç —Ö—É–∫–∞ –µ—Å–ª–∏ –Ω—É–∂–µ–Ω",
  "paragraph": "—Ç–µ–∫—Å—Ç –∞–±–∑–∞—Ü–∞ –µ—Å–ª–∏ –Ω—É–∂–µ–Ω",
  "hashtags": "#—Ç–µ–≥1 #—Ç–µ–≥2 –µ—Å–ª–∏ –Ω—É–∂–Ω—ã"
}}

–¢–û–õ–¨–ö–û JSON, –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤."""

            return system_prompt, user_prompt

        # Default
        return "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.", input_text or str(action_data)

    def _is_ad_post(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–µ–∫–ª–∞–º–Ω—ã–π –ø–æ—Å—Ç."""
        ad_markers = [
            '#—Ä–µ–∫–ª–∞–º–∞', '#ad', '#–ø—Ä–æ–º–æ', '#promo', '—Ä–µ–∫–ª–∞–º–∞',
            '–ø–µ—Ä–µ—Ö–æ–¥–∏ –ø–æ —Å—Å—ã–ª–∫–µ', '–∫—É–ø–∏—Ç—å', '—Å–∫–∏–¥–∫–∞', '–ø—Ä–æ–º–æ–∫–æ–¥',
            '–∑–∞–∫–∞–∂–∏', '–æ–ø–ª–∞—Ç–∏', '–ø–æ–¥–ø–∏—Å—ã–≤–∞–π—Å—è', '—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Å—è'
        ]
        text_lower = text.lower()
        return any(marker in text_lower for marker in ad_markers)

    def _get_system_prompt(self, purpose: str) -> str:
        """–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –ø–æ —Ç–∏–ø—É –∑–∞–¥–∞—á–∏."""
        prompts = {
            "analyze_style": "–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –∫–æ–Ω—Ç–µ–Ω—Ç–∞. –†–∞–∑–±–∏—Ä–∞–µ—à—å —Å—Ç–∏–ª—å –ø–æ—Å—Ç–æ–≤ –¥–ª—è –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä–∞.",
            "generate_draft": "–¢—ã SMM-–∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä. –ü–∏—à–µ—à—å –ø–æ—Å—Ç—ã –¥–ª—è Telegram. –í—ã–¥–µ–ª—è–π –≤–∞–∂–Ω–æ–µ –∂–∏—Ä–Ω—ã–º.",
            "research": "–¢—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –≤—ã–¥–µ–ª—è–µ—à—å –∫–ª—é—á–µ–≤–æ–µ.",
            "analyze": "–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫. –†–∞–∑–±–∏—Ä–∞–µ—à—å –¥–∞–Ω–Ω—ã–µ –∏ –¥–µ–ª–∞–µ—à—å –≤—ã–≤–æ–¥—ã.",
        }
        return prompts.get(purpose, "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.")

    def _build_prompt(self, purpose: str, input_text: str, prev_results: list, action_data: dict) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –ø–æ —Ç–∏–ø—É –∑–∞–¥–∞—á–∏."""
        if purpose == "analyze_style":
            posts = action_data.get("posts", prev_results[0] if prev_results else "")
            return f"""–†–∞–∑–±–µ—Ä–∏ —Å—Ç–∏–ª—å –ø–æ—Å—Ç–æ–≤ –¥–ª—è –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä–∞.

–ü–û–°–¢–´:
{posts}

–î–∞–π –ö–û–ù–ö–†–ï–¢–ò–ö–£:
1. HOOKS ‚Äî –∫–∞–∫ —Ü–µ–ø–ª—è—é—Ç –≤–Ω–∏–º–∞–Ω–∏–µ? –ü—Ä–∏–º–µ—Ä—ã —Ñ—Ä–∞–∑.
2. –°–¢–†–£–ö–¢–£–†–ê ‚Äî –∫–∞–∫ —Å—Ç—Ä–æ—è—Ç –ø–æ—Å—Ç?
3. –§–ò–®–ö–ò ‚Äî —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –ø—Ä–∏—ë–º—ã, —Å–ª–æ–≤–∞.
4. –ö–û–ù–¶–û–í–ö–ê ‚Äî –∫–∞–∫ –∑–∞–∫–∞–Ω—á–∏–≤–∞—é—Ç?
5. –î–õ–ò–ù–ê ‚Äî —Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤?

–ë–µ–∑ –≤–æ–¥—ã —Ç–∏–ø–∞ "–¥—Ä—É–∂–µ—Å–∫–∏–π —Ç–æ–Ω"."""

        elif purpose == "generate_draft":
            context = action_data.get("context", "")
            topic = input_text or action_data.get("topic", "")
            web_info = ""
            similar = ""

            for res in prev_results:
                if isinstance(res, dict):
                    if res.get("tool") == "web_search":
                        web_info = str(res.get("results", ""))[:1000]
                    elif res.get("tool") == "memory_search":
                        similar = str(res.get("results", ""))[:500]

            return f"""–ù–∞–ø–∏—à–∏ –ø–æ—Å—Ç –¥–ª—è Telegram-–∫–∞–Ω–∞–ª–∞.

{context}

–¢–ï–ú–ê: {topic}

{"–ü–û–•–û–ñ–ò–ï –ü–û–°–¢–´ (–≤–¥–æ—Ö–Ω–æ–≤–ª—è–π—Å—è):" + similar if similar else ""}

{"–ê–ö–¢–£–ê–õ–¨–ù–ê–Ø –ò–ù–§–ê:" + web_info if web_info else ""}

–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û:
1. –°–ª–µ–¥—É–π —Å—Ç–∏–ª—é –∫–ª–∏–µ–Ω—Ç–∞
2. –í—ã–¥–µ–ª—è–π –≤–∞–∂–Ω–æ–µ –∂–∏—Ä–Ω—ã–º
3. –ù–∞–ø–∏—à–∏ —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞"""

        elif purpose == "research":
            return f"–ò—Å—Å–ª–µ–¥—É–π —Ç–µ–º—É: {input_text}\n\n–ü—Ä–µ–¥—ã–¥—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {prev_results}"

        else:
            return input_text or str(action_data)

    def _handle_tool_call(self, step: Step, context: ExecutionContext) -> Any:
        """
        Handle tool call step.

        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç ToolRegistry –¥–ª—è –≤—ã–∑–æ–≤–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö tools.
        """
        tool_name = step.action_data.get("tool", "unknown")
        params = {k: v for k, v in step.action_data.items() if k not in ("tool", "source_step_id")}

        # –î–æ–±–∞–≤–ª—è–µ–º user_id –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –µ—Å–ª–∏ –Ω—É–∂–µ–Ω
        if "user_id" not in params:
            params["user_id"] = context.user_id

        # –û—Å–æ–±—ã–π —Å–ª—É—á–∞–π: source_step_id ‚Äî –±–µ—Ä—ë–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —à–∞–≥–∞
        source_step_id = step.action_data.get("source_step_id")

        # compute_channel_metrics ‚Äî –Ω—É–∂–Ω—ã posts –∏–∑ parse_channel
        if tool_name == "compute_channel_metrics" and source_step_id:
            source_result = context.get_step_result(source_step_id)
            if source_result and isinstance(source_result, dict):
                posts = source_result.get("posts", [])
                params["posts"] = posts

        # memory_store ‚Äî –±–µ—Ä—ë–º response –∏–∑ LLM
        if tool_name == "memory_store" and source_step_id:
            source_result = context.get_step_result(source_step_id)
            if source_result and isinstance(source_result, dict):
                response_content = source_result.get("response", "")
                channel = step.action_data.get("input_text", "channel")
                params["content"] = f"–°—Ç–∏–ª—å –∫–∞–Ω–∞–ª–∞ {channel}: {response_content[:1500]}"
                # –î–æ–±–∞–≤–ª—è–µ–º –≤–µ—Ä—Å–∏—é –∞–Ω–∞–ª–∏–∑–∞ –≤ metadata
                params["metadata"] = {"analysis_version": "v2", "channel": channel}

        # –ü—Ä–æ–±—É–µ–º –≤—ã–∑–≤–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π tool
        tool_spec = tool_registry.get(tool_name)
        if tool_spec is not None:
            try:
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ tool –ø—Ä–∏–Ω–∏–º–∞–µ—Ç
                import inspect
                sig = inspect.signature(tool_spec.handler)
                valid_params = set(sig.parameters.keys())
                filtered_params = {k: v for k, v in params.items() if k in valid_params}

                print(f"[Step] TOOL_CALL: {tool_name} —Å {list(filtered_params.keys())}")
                result = tool_spec.handler(**filtered_params)
                print(f"[Step] TOOL_CALL: {tool_name} ‚Üí OK")
                return {"tool": tool_name, **result}
            except Exception as e:
                print(f"[Step] TOOL_CALL: {tool_name} ‚Üí ERROR: {e}")
                return {"tool": tool_name, "error": str(e)}

        # Fallback: mock responses –¥–ª—è –Ω–µ–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö tools
        print(f"[Step] TOOL_CALL: {tool_name} ‚Üí MOCK (not registered)")
        mock_responses = {
            "web_fetch": {
                "tool": "web_fetch",
                "content": "Fetched page content...",
                "url": step.action_data.get("url"),
            },
            "telegram_publish": {
                "tool": "telegram_publish",
                "success": True,
                "message_id": 12345,
                "channel": step.action_data.get("channel"),
            },
        }

        return mock_responses.get(tool_name, {"tool": tool_name, "result": "mock"})

    def _handle_approval(self, step: Step, context: ExecutionContext) -> Any:
        """
        Handle approval step.

        Pauses task execution and waits for user approval.
        """
        message = step.action_data.get("message", "Approval required")

        # Get draft content if referenced
        draft_step_id = step.action_data.get("draft_step_id")
        draft_content = None
        if draft_step_id:
            draft_result = context.get_step_result(draft_step_id)
            if draft_result:
                draft_content = draft_result.get("response")

        # Pause task for approval
        self.task_manager.pause(
            context.task_id,
            PauseReason.APPROVAL,
            data={
                "step_id": step.step_id,
                "message": message,
                "draft_content": draft_content,
            }
        )

        # Raise to stop execution
        raise ApprovalRequired(message, step.step_id, draft_content)

    def _handle_condition(self, step: Step, context: ExecutionContext) -> Any:
        """Handle conditional step."""
        condition = step.action_data.get("condition", "true")

        # MVP: Simple evaluation
        result = True

        return {
            "condition": condition,
            "result": result,
            "branch": "true" if result else "false",
        }

    def _handle_aggregate(self, step: Step, context: ExecutionContext) -> Any:
        """Handle aggregation step."""
        step_ids = step.action_data.get("step_ids", [])

        aggregated = {}
        for step_id in step_ids:
            result = context.get_step_result(step_id)
            if result:
                aggregated[step_id] = result

        return {
            "aggregated": aggregated,
            "count": len(aggregated),
        }
