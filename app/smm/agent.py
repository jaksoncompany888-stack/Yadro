"""
SMM Agent - –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –≤–µ—Ä—Å–∏—è

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç Executor ‚Üí Plan ‚Üí Steps –¥–ª—è –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π:
- Layer 2: Kernel (TaskManager)
- Layer 3: Executor (Plan, Step)
- Layer 4: Tools (ToolRegistry)
- Layer 5: LLM
- Layer 6: Memory (FTS5)
"""
import re
from dataclasses import dataclass
from typing import Optional, List
from datetime import datetime, timedelta

from app.storage import Database
from app.kernel import TaskManager, PauseReason
from app.kernel.models import TaskStatus
from app.scheduler import Scheduler
from app.memory import MemoryService, MemoryType
from app.llm import LLMService, Message
from app.executor import Executor, PlanManager, StepExecutor
from app.executor.step_executor import ApprovalRequired, _markdown_to_html
from app.tools.channel_parser import ChannelParser
from app.tools.news_monitor import NewsMonitor


@dataclass
class PostDraft:
    text: str
    topic: str
    task_id: int = 0
    channel_id: str = ""


class SMMAgent:
    """
    SMM Agent ‚Äî –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –≤–µ—Ä—Å–∏—è.

    –í—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è —á–µ—Ä–µ–∑ Executor ‚Üí Plan ‚Üí Steps.
    """

    def __init__(self, db: Database, llm: LLMService):
        self.db = db
        self.llm = llm
        self.tasks = TaskManager(db=db)
        self.scheduler = Scheduler(db=db)
        self.memory = MemoryService(db=db)
        self._parser = None
        self._news = None
        self._executor = None

    @property
    def executor(self) -> Executor:
        """Executor –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á —á–µ—Ä–µ–∑ Plan/Step."""
        if self._executor is None:
            step_executor = StepExecutor(
                task_manager=self.tasks,
                llm_service=self.llm
            )
            self._executor = Executor(
                db=self.db,
                task_manager=self.tasks,
                step_executor=step_executor,
            )
        return self._executor

    @property
    def parser(self) -> ChannelParser:
        if self._parser is None:
            self._parser = ChannelParser()
        return self._parser

    @property
    def news(self) -> NewsMonitor:
        if self._news is None:
            self._news = NewsMonitor()
        return self._news

    # ==================== –ü–ê–ú–Ø–¢–¨ ====================

    def save_style(self, user_id: int, style: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç–∏–ª—å –ø–æ—Å—Ç–æ–≤."""
        self.db.execute(
            "DELETE FROM memory_items WHERE user_id = ? AND content LIKE '–°—Ç–∏–ª—å:%'",
            (user_id,)
        )
        self.memory.store_fact(user_id, f"–°—Ç–∏–ª—å: {style}", importance=1.0)

    def save_channel(self, user_id: int, channel_id: str, channel_name: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–Ω–∞–ª –∫–ª–∏–µ–Ω—Ç–∞."""
        self.db.execute(
            "DELETE FROM memory_items WHERE user_id = ? AND content LIKE '–ö–∞–Ω–∞–ª:%'",
            (user_id,)
        )
        self.memory.store_fact(
            user_id,
            f"–ö–∞–Ω–∞–ª: {channel_name} (ID: {channel_id})",
            importance=1.0
        )

    def add_competitor(self, user_id: int, channel: str, auto_analyze: bool = True):
        """–î–æ–±–∞–≤–∏—Ç—å –∫–∞–Ω–∞–ª –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ Executor."""
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–ª–∏–∞—Å—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ)
        aliases = self._generate_channel_aliases(channel)

        self.memory.store(
            user_id=user_id,
            content=f"–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç: {channel}",
            memory_type=MemoryType.FACT,
            importance=0.8,
            metadata={"aliases": aliases, "channel": channel}
        )

        print(f"[Memory] –î–æ–±–∞–≤–ª–µ–Ω –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç {channel}, –∞–ª–∏–∞—Å—ã: {aliases[:3]}...")

        if auto_analyze:
            self._analyze_channel_via_executor(user_id, channel)

    def _generate_channel_aliases(self, channel: str) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–ª–∏–∞—Å–æ–≤ –∫–∞–Ω–∞–ª–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ)."""
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –±–µ–∑ @
        name = channel.replace('@', '').lower()

        aliases = [name]

        # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏
        aliases.extend(self._get_translit_variants(name))

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä—É—Å—Å–∫—É—é —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—é (–ª–∞—Ç–∏–Ω–∏—Ü–∞ ‚Üí –∫–∏—Ä–∏–ª–ª–∏—Ü–∞)
        rus_translit = self._translit_to_russian(name)
        if rus_translit:
            aliases.append(rus_translit)

        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        return list(set(aliases))

    def _translit_to_russian(self, text: str) -> str:
        """–¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –ª–∞—Ç–∏–Ω–∏—Ü—ã –≤ –∫–∏—Ä–∏–ª–ª–∏—Ü—É (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ)."""
        # –°–Ω–∞—á–∞–ª–∞ –º–Ω–æ–≥–æ–±—É–∫–≤–µ–Ω–Ω—ã–µ —Å–æ—á–µ—Ç–∞–Ω–∏—è
        multi_map = {
            'sch': '—â', 'sh': '—à', 'ch': '—á', 'zh': '–∂', 'ts': '—Ü',
            'yu': '—é', 'ya': '—è', 'yo': '—ë', 'ye': '–µ',
            'ow': '–æ—É', 'ew': '—å—é', 'oo': '—É', 'ee': '–∏',
        }
        result = text.lower()
        for lat, rus in multi_map.items():
            result = result.replace(lat, rus)

        # –ü–æ—Ç–æ–º –æ–¥–Ω–æ–±—É–∫–≤–µ–Ω–Ω—ã–µ
        single_map = {
            'a': '–∞', 'b': '–±', 'c': '–∫', 'd': '–¥', 'e': '–µ', 'f': '—Ñ',
            'g': '–≥', 'h': '—Ö', 'i': '–∏', 'j': '–¥–∂', 'k': '–∫', 'l': '–ª',
            'm': '–º', 'n': '–Ω', 'o': '–æ', 'p': '–ø', 'q': '–∫', 'r': '—Ä',
            's': '—Å', 't': '—Ç', 'u': '—É', 'v': '–≤', 'w': '–≤', 'x': '–∫—Å',
            'y': '–π', 'z': '–∑',
        }
        for lat, rus in single_map.items():
            result = result.replace(lat, rus)

        return result

    def _analyze_channel_via_executor(self, user_id: int, channel: str) -> bool:
        """
        –ê–Ω–∞–ª–∏–∑ –∫–∞–Ω–∞–ª–∞ —á–µ—Ä–µ–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É Executor ‚Üí Plan ‚Üí Steps.

        Plan (smm_analyze):
        1. TOOL_CALL: parse_channel
        2. LLM_CALL: smm_analyze_style
        3. TOOL_CALL: memory_store

        Returns: True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –µ—Å–ª–∏ –æ—à–∏–±–∫–∞
        """
        print(f"\n[Executor] === –ê–Ω–∞–ª–∏–∑ {channel} ===")

        try:
            # –°–æ–∑–¥–∞—ë–º –∑–∞–¥–∞—á—É
            task = self.tasks.enqueue(
                user_id=user_id,
                task_type="smm_analyze",
                input_text=channel,
                input_data={
                    "user_id": user_id,
                    "channel": channel,
                }
            )

            # –ù–∞–ø—Ä—è–º—É—é –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ running
            from datetime import datetime, timezone, timedelta
            now = datetime.now(timezone.utc)
            lease_expires = now + timedelta(seconds=300)

            self.db.execute(
                """UPDATE tasks
                   SET status = 'running', locked_by = ?, locked_at = ?,
                       lease_expires_at = ?, started_at = ?, updated_at = ?
                   WHERE id = ?""",
                ("smm_agent", now.isoformat(), lease_expires.isoformat(),
                 now.isoformat(), now.isoformat(), task.id)
            )

            running_task = self.tasks.get_task(task.id)
            if running_task:
                self.executor.run_task(running_task)

            print(f"[Executor] === –ì–æ—Ç–æ–≤–æ: {channel} ===\n")
            return True

        except Exception as e:
            print(f"[Executor] –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {channel}: {e}")
            return False

    def add_news_source(self, user_id: int, url: str, name: str = ""):
        """–î–æ–±–∞–≤–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–æ–≤–æ—Å—Ç–µ–π."""
        source_name = name or url
        self.memory.store_fact(
            user_id,
            f"–ò—Å—Ç–æ—á–Ω–∏–∫: {source_name} | {url}",
            importance=0.8
        )

    def get_news_sources(self, user_id: int) -> list:
        """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        facts = self.memory.get_facts(user_id)
        sources = []
        for f in facts:
            if f.content.startswith("–ò—Å—Ç–æ—á–Ω–∏–∫:"):
                parts = f.content.replace("–ò—Å—Ç–æ—á–Ω–∏–∫:", "").strip().split(" | ")
                if len(parts) == 2:
                    sources.append({"name": parts[0], "url": parts[1]})
                else:
                    sources.append({"name": parts[0], "url": parts[0]})
        return sources

    def remove_news_source(self, user_id: int, url: str):
        """–£–¥–∞–ª–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫."""
        self.db.execute(
            "DELETE FROM memory_items WHERE user_id = ? AND content LIKE ?",
            (user_id, f"%{url}%")
        )

    def get_competitors(self, user_id: int) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤."""
        facts = self.memory.get_facts(user_id)
        competitors = []
        for f in facts:
            if f.content.startswith("–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç:"):
                ch = f.content.replace("–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç:", "").strip()
                competitors.append(ch)
        return competitors

    def get_competitors_with_ids(self, user_id: int) -> List[dict]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ —Å ID –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è."""
        rows = self.db.fetch_all(
            """SELECT id, content FROM memory_items
               WHERE user_id = ? AND content LIKE '–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç:%'""",
            (user_id,)
        )
        result = []
        for row in rows:
            channel = row[1].replace("–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç:", "").strip()
            result.append({"id": row[0], "channel": channel})
        return result

    def remove_competitor(self, memory_id: int):
        """–£–¥–∞–ª–∏—Ç—å –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ –ø–æ ID."""
        self.db.execute("DELETE FROM memory_items WHERE id = ?", (memory_id,))

    def save_successful_post(self, user_id: int, post_text: str, metrics: dict = None):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —É–¥–∞—á–Ω—ã–π –ø–æ—Å—Ç."""
        content = f"–£–¥–∞—á–Ω—ã–π –ø–æ—Å—Ç: {post_text[:200]}"
        if metrics:
            content += f" | –ü—Ä–æ—Å–º–æ—Ç—Ä—ã: {metrics.get('views', '?')}"
        self.memory.store_decision(user_id, content, importance=0.8)

    def save_feedback(self, user_id: int, feedback: str, post_text: str = ""):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∏–¥–±–µ–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è."""
        content = f"–§–∏–¥–±–µ–∫: {feedback}"
        if post_text:
            content += f" | –ü–æ—Å—Ç: {post_text[:100]}"
        self.memory.store(
            user_id=user_id,
            content=content,
            memory_type=MemoryType.FEEDBACK,
            importance=0.9
        )

    def get_channel_id(self, user_id: int) -> Optional[str]:
        """–ü–æ–ª—É—á–∏—Ç—å ID –∫–∞–Ω–∞–ª–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        facts = self.memory.get_facts(user_id)
        for f in facts:
            if "–ö–∞–Ω–∞–ª:" in f.content and "ID:" in f.content:
                match = re.search(r'ID: ([^\)]+)', f.content)
                if match:
                    return match.group(1)
        return None

    def get_base_style(self, user_id: int) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –±–∞–∑–æ–≤—ã–π —Å—Ç–∏–ª—å –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫."""
        style = self.db.fetch_one(
            "SELECT content FROM memory_items WHERE user_id = ? AND content LIKE '–°—Ç–∏–ª—å:%' ORDER BY created_at DESC LIMIT 1",
            (user_id,)
        )
        if style:
            return style[0].replace('–°—Ç–∏–ª—å:', '').strip()
        return ""

    def _find_relevant_channel_styles(self, user_id: int, topic: str, limit: int = 3) -> List[str]:
        """
        –ù–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å—Ç–∏–ª–∏ –∫–∞–Ω–∞–ª–æ–≤ –ø–æ —Ç–µ–º–µ –ø–æ—Å—Ç–∞ (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ, —á–µ—Ä–µ–∑ FTS5).

        –ï—Å–ª–∏ —Ç–µ–º–∞ "—Ä–µ—Ç—Ä–æ–≥—Ä–∞–¥–Ω—ã–π –º–µ—Ä–∫—É—Ä–∏–π" ‚Äî –Ω–∞–π–¥—ë—Ç —Å—Ç–∏–ª–∏ –∫–∞–Ω–∞–ª–æ–≤ –ø—Ä–æ –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—é.
        –ï—Å–ª–∏ —Ç–µ–º–∞ "–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏ –≤ –∞–∫—Ü–∏–∏" ‚Äî –Ω–∞–π–¥—ë—Ç —Å—Ç–∏–ª–∏ –∫–∞–Ω–∞–ª–æ–≤ –ø—Ä–æ —Ñ–∏–Ω–∞–Ω—Å—ã.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–æ `limit` —Å–∞–º—ã—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–∏–ª–µ–π.
        """
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–º—ã (–±–µ–∑ —Å—Ç–æ–ø-—Å–ª–æ–≤)
        stop_words = {'–∏', '–≤', '–Ω–∞', '—Å', '—á—Ç–æ', '—ç—Ç–æ', '–∫–∞–∫', '–∞', '–Ω–µ', '–Ω–æ', '–¥–ª—è', '–ø–æ',
                      '–ø–æ—Å—Ç', '–ø—Ä–æ', '–æ', '–æ–±', '–Ω–∞–ø–∏—à–∏', '—Å–¥–µ–ª–∞–π', '—Å–æ–∑–¥–∞–π', '—Ç–µ–º—É', '—Ç–µ–º–∞'}
        words = re.findall(r'\b[–∞-—è–ê-–Ø—ë–Åa-zA-Z]{3,}\b', topic.lower())
        keywords = [w for w in words if w not in stop_words][:5]

        if not keywords:
            return []

        # –ò—â–µ–º –≤ FTS5 —Å—Ä–µ–¥–∏ —Å—Ç–∏–ª–µ–π –∫–∞–Ω–∞–ª–æ–≤
        search_query = " OR ".join(keywords)

        try:
            results = self.db.fetch_all(
                """SELECT m.content FROM memory_items m
                   JOIN memory_fts f ON m.id = f.rowid
                   WHERE m.user_id = ?
                   AND m.content LIKE '–°—Ç–∏–ª—å –∫–∞–Ω–∞–ª–∞%'
                   AND memory_fts MATCH ?
                   ORDER BY rank
                   LIMIT ?""",
                (user_id, search_query, limit)
            )
            if results:
                print(f"[Context] –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–∏–ª–µ–π –ø–æ —Ç–µ–º–µ: {keywords}")
                return [r[0] for r in results]
        except Exception as e:
            print(f"[Context] FTS5 –ø–æ–∏—Å–∫ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")

        return []

    def _extract_channel_from_topic(self, topic: str, user_id: int = None) -> Optional[str]:
        """
        –ò–∑–≤–ª–µ—á—å –∫–∞–Ω–∞–ª –∏–∑ —Ç–µ–º—ã –ø–æ—Å—Ç–∞ (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ, –±–µ–∑ LLM).

        –ü–∞—Ç—Ç–µ—Ä–Ω—ã:
        - "–≤ —Å—Ç–∏–ª–µ @channel"
        - "–∫–∞–∫ @channel"
        - "–≤ —Å—Ç–∏–ª–µ –º–µ–≥–∞–º–∞—Ä–∫–µ—Ç–∞" ‚Üí –∏—â–µ–º –≤ –ø–∞–º—è—Ç–∏
        - "@channel"
        """
        topic_lower = topic.lower()

        # 1. –ò—â–µ–º —è–≤–Ω—ã–π @channel
        match = re.search(r'@([\w_]+)', topic)
        if match:
            return f"@{match.group(1)}"

        # 2. –ò—â–µ–º "–≤ —Å—Ç–∏–ª–µ X", "–∫–∞–∫ X" –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤ –ø–∞–º—è—Ç–∏
        patterns = [
            r'–≤ —Å—Ç–∏–ª–µ\s+(\S+)',
            r'–∫–∞–∫\s+—É?\s*(\S+)',
            r'—Å—Ç–∏–ª—å\s+(\S+)',
        ]

        for pattern in patterns:
            match = re.search(pattern, topic_lower)
            if match:
                keyword = match.group(1).strip('.,!?')

                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—â–∏–µ —Å–ª–æ–≤–∞
                skip_words = {'—ç—Ç–æ–≥–æ', '—Ç–æ–≥–æ', '–∫–∞–Ω–∞–ª–∞', '–ø–æ—Å—Ç–∞', '—Ç–µ–∫—Å—Ç–∞', '–æ–±—ã—á–Ω–æ', '–≤—Å–µ–≥–¥–∞'}
                if keyword in skip_words:
                    continue

                # –ï—Å–ª–∏ –µ—Å—Ç—å user_id ‚Äî –∏—â–µ–º –∫–∞–Ω–∞–ª –≤ –ø–∞–º—è—Ç–∏ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É
                if user_id:
                    found_channel = self._find_channel_by_keyword(user_id, keyword)
                    if found_channel:
                        print(f"[Context] –ù–∞–π–¥–µ–Ω –∫–∞–Ω–∞–ª '{found_channel}' –ø–æ —Å–ª–æ–≤—É '{keyword}'")
                        return found_channel

                # Fallback: –µ—Å–ª–∏ —Å–ª–æ–≤–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –∫–∞–Ω–∞–ª
                if keyword.startswith('@'):
                    return keyword

        return None

    def _find_channel_by_keyword(self, user_id: int, keyword: str) -> Optional[str]:
        """–ù–∞–π—Ç–∏ –∫–∞–Ω–∞–ª –≤ –ø–∞–º—è—Ç–∏ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ)."""
        import json

        # –ò—â–µ–º —Å—Ä–µ–¥–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –∏ —Å—Ç–∏–ª–µ–π –∫–∞–Ω–∞–ª–æ–≤
        rows = self.db.fetch_all(
            """SELECT content, metadata FROM memory_items
               WHERE user_id = ?
               AND (content LIKE '–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç:%' OR content LIKE '–°—Ç–∏–ª—å –∫–∞–Ω–∞–ª–∞%')""",
            (user_id,)
        )

        keyword_lower = keyword.lower()
        keyword_translit = self._translit(keyword_lower)

        for content, metadata_str in rows:
            content_lower = content.lower()

            # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–ª–∏–∞—Å—ã –∏–∑ metadata (–±—ã—Å—Ç—Ä—ã–π –ø—É—Ç—å)
            if metadata_str:
                try:
                    metadata = json.loads(metadata_str)
                    aliases = metadata.get("aliases", [])
                    channel = metadata.get("channel", "")

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –∞–ª–∏–∞—Å–∞–º–∏
                    for alias in aliases:
                        if (keyword_lower in alias or
                            alias in keyword_lower or
                            keyword_translit in alias or
                            self._fuzzy_match(keyword_lower, alias)):
                            print(f"[Context] –ù–∞–π–¥–µ–Ω –ø–æ –∞–ª–∏–∞—Å—É: {keyword} ‚Üí {channel}")
                            return channel
                except:
                    pass

            # 2. Fallback: –ø–æ–∏—Å–∫ –ø–æ content (–¥–ª—è —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π –±–µ–∑ metadata)
            channel_match = re.search(r'@([\w_]+)', content)
            channel_name = channel_match.group(1).lower() if channel_match else ""

            match_found = (
                keyword_lower in content_lower or
                keyword_lower in channel_name or
                keyword_translit in channel_name or
                self._translit(channel_name) in keyword_lower or
                self._fuzzy_match(keyword_lower, channel_name)
            )

            if match_found:
                if channel_match:
                    return f"@{channel_match.group(1)}"
                if '–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç:' in content_lower:
                    return content.replace('–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç:', '').strip()

        return None

    def _translit(self, text: str) -> str:
        """–¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã –≤ –ª–∞—Ç–∏–Ω–∏—Ü—É (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ)."""
        translit_map = {
            '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd', '–µ': 'e', '—ë': 'e',
            '–∂': 'zh', '–∑': 'z', '–∏': 'i', '–π': 'y', '–∫': 'k', '–ª': 'l', '–º': 'm',
            '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't', '—É': 'u',
            '—Ñ': 'f', '—Ö': 'h', '—Ü': 'ts', '—á': 'ch', '—à': 'sh', '—â': 'sch',
            '—ä': '', '—ã': 'y', '—å': '', '—ç': 'e', '—é': 'yu', '—è': 'ya',
        }
        result = ""
        for char in text.lower():
            result += translit_map.get(char, char)
        return result

    def _fuzzy_match(self, keyword: str, channel: str) -> bool:
        """–ù–µ—á—ë—Ç–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ) ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—Ö–æ–∂–µ—Å—Ç—å."""
        if not keyword or not channel:
            return False

        # –£–±–∏—Ä–∞–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
        kw = keyword.replace('_', '').replace('-', '').replace(' ', '')
        ch = channel.replace('_', '').replace('-', '').replace(' ', '')

        # 1. –ü—Ä—è–º–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ
        if kw in ch or ch in kw:
            return True

        # 2. –í–∞—Ä–∏–∞—Ü–∏–∏ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏ (–æ—É/ow, —É/u/ou)
        kw_variants = self._get_translit_variants(kw)
        for variant in kw_variants:
            if variant in ch or ch in variant:
                return True

        # 3. –ú–∏–Ω–∏–º—É–º 60% –æ–±—â–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ (–¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–ª–æ–≤)
        if len(kw) >= 4 and len(ch) >= 4:
            common = sum(1 for c in kw if c in ch)
            similarity = common / max(len(kw), len(ch))
            if similarity >= 0.6:
                return True

        return False

    def _get_translit_variants(self, text: str) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏ (–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ)."""
        variants = [text]

        # –ß–∞—Å—Ç—ã–µ –∑–∞–º–µ–Ω—ã
        replacements = [
            ('ou', 'ow'), ('ow', 'ou'),
            ('u', 'ou'), ('ou', 'u'),
            ('k', 'c'), ('c', 'k'),
            ('ks', 'x'), ('x', 'ks'),
            ('i', 'y'), ('y', 'i'),
            ('ph', 'f'), ('f', 'ph'),
        ]

        for old, new in replacements:
            if old in text:
                variants.append(text.replace(old, new))

        return variants

    def build_smm_context(self, user_id: int, extra_style: str = "", target_channel: str = None, topic: str = None) -> str:
        """
        –°–æ–±—Ä–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:
        1. –°—Ç–∏–ª—å = –±–∞–∑–∞ + –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è
        2. –ü—Ä–∏–º–µ—Ä—ã —É—Å–ø–µ—à–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
        3. –ò–Ω—Å–∞–π—Ç—ã –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –ø–æ —Ç–µ–º–µ –∏–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π)
        4. –§–∏–¥–±–µ–∫

        Args:
            target_channel: –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω ‚Äî –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¢–û–õ–¨–ö–û —Å—Ç–∏–ª—å —ç—Ç–æ–≥–æ –∫–∞–Ω–∞–ª–∞
            topic: —Ç–µ–º–∞ –ø–æ—Å—Ç–∞ ‚Äî –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ —Å—Ç–∏–ª—è —á–µ—Ä–µ–∑ FTS5
        """
        parts = []

        # 1. –°–¢–ò–õ–¨
        base_style = self.get_base_style(user_id)
        if base_style or extra_style:
            style_text = base_style
            if extra_style:
                style_text = f"{base_style}. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: {extra_style}" if base_style else extra_style
            parts.append(f"–°–¢–ò–õ–¨:\n{style_text}")

        # 2. –ü–†–ò–ú–ï–†–´ –£–°–ü–ï–®–ù–´–• –ü–û–°–¢–û–í
        published = self.db.fetch_all(
            """SELECT content FROM memory_items
               WHERE user_id = ?
               AND (content LIKE '–û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Å—Ç:%' OR content LIKE '–£–¥–∞—á–Ω—ã–π –ø–æ—Å—Ç:%')
               ORDER BY created_at DESC LIMIT 5""",
            (user_id,)
        )
        if published:
            examples = []
            for row in published:
                text = row[0]
                for prefix in ['–û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Å—Ç:', '–£–¥–∞—á–Ω—ã–π –ø–æ—Å—Ç:']:
                    text = text.replace(prefix, '').strip()
                if '|' in text:
                    text = text.split('|')[0].strip()
                examples.append(f"‚Ä¢ {text[:400]}")
            parts.append(f"–ü–†–ò–ú–ï–†–´ –ü–û–°–¢–û–í –ö–û–¢–û–†–´–ï –ó–ê–®–õ–ò:\n" + "\n".join(examples))

        # 3. –°–¢–ò–õ–ò –ö–ê–ù–ê–õ–û–í ‚Äî –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –ø–æ —Ç–µ–º–µ, –∏–ª–∏ –≤—Å–µ
        if target_channel:
            # –¢–æ–ª—å–∫–æ —Å—Ç–∏–ª—å —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞
            channel_clean = target_channel.replace('@', '')
            channel_style = self.db.fetch_one(
                """SELECT content FROM memory_items
                   WHERE user_id = ?
                   AND (content LIKE ? OR content LIKE ?)
                   ORDER BY created_at DESC LIMIT 1""",
                (user_id, f"–°—Ç–∏–ª—å –∫–∞–Ω–∞–ª–∞ %{channel_clean}%", f"–°—Ç–∏–ª—å –∫–∞–Ω–∞–ª–∞ @{channel_clean}%")
            )
            if channel_style:
                parts.append(f"–°–¢–ò–õ–¨ –ö–ê–ù–ê–õ–ê {target_channel} (–ü–ò–®–ò –ò–ú–ï–ù–ù–û –í –≠–¢–û–ú –°–¢–ò–õ–ï):\n{channel_style[0][:800]}")
        elif topic:
            # –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–∏–ª–µ–π –ø–æ —Ç–µ–º–µ —á–µ—Ä–µ–∑ FTS5 (–¥–æ 3 –∫–∞–Ω–∞–ª–æ–≤)
            relevant_styles = self._find_relevant_channel_styles(user_id, topic, limit=3)
            if relevant_styles:
                styles_text = "\n---\n".join([s[:400] for s in relevant_styles])
                parts.append(f"–†–ï–õ–ï–í–ê–ù–¢–ù–´–ï –°–¢–ò–õ–ò (–ø–æ —Ç–µ–º–µ):\n{styles_text}")
                print(f"[Context] FTS5: –Ω–∞–π–¥–µ–Ω–æ {len(relevant_styles)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–∏–ª–µ–π")
            else:
                # Fallback ‚Äî –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ —Å—Ç–∏–ª–∏ (–æ–±–∞ —Ñ–æ—Ä–º–∞—Ç–∞)
                channel_styles = self.db.fetch_all(
                    """SELECT content FROM memory_items
                       WHERE user_id = ?
                       AND content LIKE '–°—Ç–∏–ª—å –∫–∞–Ω–∞–ª–∞%'
                       ORDER BY created_at DESC LIMIT 2""",
                    (user_id,)
                )
                if channel_styles:
                    styles_text = "\n---\n".join([s[0][:400] for s in channel_styles])
                    parts.append(f"–°–¢–ò–õ–ò –ö–ê–ù–ê–õ–û–í:\n{styles_text}")
                    print(f"[Context] Fallback: –Ω–∞–π–¥–µ–Ω–æ {len(channel_styles)} —Å—Ç–∏–ª–µ–π")
        else:
            # –í—Å–µ —Å—Ç–∏–ª–∏ –∫–∞–Ω–∞–ª–æ–≤ (fallback)
            channel_styles = self.db.fetch_all(
                """SELECT content FROM memory_items
                   WHERE user_id = ?
                   AND content LIKE '–°—Ç–∏–ª—å –∫–∞–Ω–∞–ª–∞%'
                   ORDER BY created_at DESC LIMIT 3""",
                (user_id,)
            )
            if channel_styles:
                insights = [row[0][:350] for row in channel_styles]
                parts.append(f"–°–¢–ò–õ–ò –ö–ê–ù–ê–õ–û–í:\n" + "\n---\n".join(insights))

        # 4. –¢–ò–ü–ò–ß–ù–´–ï –ü–†–ê–í–ö–ò –ö–õ–ò–ï–ù–¢–ê
        edits = self.db.fetch_all(
            """SELECT content FROM memory_items
               WHERE user_id = ?
               AND (content LIKE '–§–∏–¥–±–µ–∫:%' OR content LIKE '–ü—Ä–∏–º–µ—Ä –ø—Ä–∞–≤–∫–∏:%')
               ORDER BY created_at DESC LIMIT 10""",
            (user_id,)
        )
        if edits:
            patterns = self._analyze_edit_patterns([row[0] for row in edits])
            if patterns:
                parts.append(f"–í–ê–ñ–ù–û ‚Äî –ö–õ–ò–ï–ù–¢ –û–ë–´–ß–ù–û –ü–†–û–°–ò–¢:\n{patterns}")

        return "\n\n".join(parts) if parts else ""

    def _analyze_edit_patterns(self, edits: list) -> str:
        """–ê–Ω–∞–ª–∏–∑ —Ç–∏–ø–∏—á–Ω—ã—Ö –ø—Ä–∞–≤–æ–∫ –∫–ª–∏–µ–Ω—Ç–∞."""
        counters = {
            'short': 0, 'long': 0, 'emoji_add': 0, 'emoji_remove': 0,
            'simple': 0, 'bold': 0, 'official': 0, 'soft': 0,
            'structure': 0, 'cta': 0
        }

        keywords = {
            'short': ['–∫–æ—Ä–æ—á', '—Å–æ–∫—Ä–∞—Ç', '–º–µ–Ω—å—à–µ —Ç–µ–∫—Å—Ç', '—É–±–µ—Ä–∏ –ª–∏—à–Ω', '–∫–æ–º–ø–∞–∫—Ç–Ω'],
            'long': ['–¥–ª–∏–Ω–Ω', '–±–æ–ª—å—à–µ —Ç–µ–∫—Å—Ç', '—Ä–∞–∑–≤–µ—Ä–Ω', '–ø–æ–¥—Ä–æ–±–Ω', '–¥–æ–±–∞–≤—å'],
            'emoji_add': ['–¥–æ–±–∞–≤—å —ç–º–æ–¥–∑–∏', '—ç–º–æ–¥–∑–∏', '—Å–º–∞–π–ª'],
            'emoji_remove': ['–±–µ–∑ —ç–º–æ–¥–∑–∏', '—É–±–µ—Ä–∏ —ç–º–æ–¥–∑–∏', '—É–±–µ—Ä–∏ —Å–º–∞–π–ª'],
            'simple': ['–ø—Ä–æ—â–µ', '–ø–æ–Ω—è—Ç–Ω', '–ª–µ–≥—á–µ'],
            'bold': ['–¥–µ—Ä–∑–∫', '–¥–µ—Ä–∑—á', '–ø—Ä–æ–≤–æ–∫–∞—Ü', '–∂—ë—Å—Ç—á', '–∂–µ—Å—Ç—á', '—Å–º–µ–ª'],
            'official': ['–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω', '—Ñ–æ—Ä–º–∞–ª—å–Ω', '—Å–µ—Ä—å—ë–∑–Ω', '—Å–µ—Ä—å–µ–∑–Ω'],
            'soft': ['–º—è–≥—á–µ', '–Ω–µ–∂–Ω', '–∞–∫–∫—É—Ä–∞—Ç–Ω'],
            'structure': ['—Å—Ç—Ä—É–∫—Ç—É—Ä', '—Å–ø–∏—Å–∫', '–ø—É–Ω–∫—Ç', '—Ä–∞–∑–¥–µ–ª'],
            'cta': ['–ø—Ä–∏–∑—ã–≤', 'call to action', '–¥–µ–π—Å—Ç–≤–∏']
        }

        for edit in edits:
            edit_lower = edit.lower()
            for category, words in keywords.items():
                if any(w in edit_lower for w in words):
                    counters[category] += 1

        insights = []
        if counters['short'] >= 2:
            insights.append("‚Ä¢ –ü–∏—à–∏ –ö–û–†–û–ß–ï ‚Äî –∫–ª–∏–µ–Ω—Ç —á–∞—Å—Ç–æ –ø—Ä–æ—Å–∏—Ç —Å–æ–∫—Ä–∞—Ç–∏—Ç—å")
        if counters['long'] >= 2:
            insights.append("‚Ä¢ –ü–∏—à–∏ –î–õ–ò–ù–ù–ï–ï –∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ")
        if counters['emoji_add'] >= 2 and counters['emoji_remove'] < 2:
            insights.append("‚Ä¢ –î–æ–±–∞–≤–ª—è–π —ç–º–æ–¥–∑–∏")
        if counters['emoji_remove'] >= 1:
            insights.append("‚Ä¢ –ë–ï–ó —ç–º–æ–¥–∑–∏")
        if counters['simple'] >= 2:
            insights.append("‚Ä¢ –ü–∏—à–∏ –ü–†–û–©–ï –∏ –ø–æ–Ω—è—Ç–Ω–µ–µ")
        if counters['bold'] >= 1:
            insights.append("‚Ä¢ –¢–æ–Ω –¥–µ—Ä–∑–∫–∏–π, –ø—Ä–æ–≤–æ–∫–∞—Ü–∏–æ–Ω–Ω—ã–π, —Å–º–µ–ª—ã–π")
        if counters['official'] >= 1:
            insights.append("‚Ä¢ –¢–æ–Ω –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π, —Å–µ—Ä—å—ë–∑–Ω—ã–π")
        if counters['soft'] >= 1:
            insights.append("‚Ä¢ –¢–æ–Ω –º—è–≥–∫–∏–π, –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π")
        if counters['structure'] >= 1:
            insights.append("‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É: —Å–ø–∏—Å–∫–∏, –ø—É–Ω–∫—Ç—ã")
        if counters['cta'] >= 1:
            insights.append("‚Ä¢ –î–æ–±–∞–≤–ª—è–π –ø—Ä–∏–∑—ã–≤ –∫ –¥–µ–π—Å—Ç–≤–∏—é")

        return "\n".join(insights) if insights else ""

    # ==================== –ì–ï–ù–ï–†–ê–¶–ò–Ø –ß–ï–†–ï–ó EXECUTOR ====================

    def generate_post(self, user_id: int, topic: str, style: str = None) -> PostDraft:
        """
        –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å—Ç —á–µ—Ä–µ–∑ Executor ‚Üí Plan ‚Üí Steps.

        Plan (smm_generate):
        1. TOOL_CALL: memory_search ‚Äî –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö
        2. TOOL_CALL: web_search ‚Äî –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–∞
        3. LLM_CALL: smm_generate_post ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        4. APPROVAL ‚Äî –ø–∞—É–∑–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç PostDraft —Å —Ç–µ–∫—Å—Ç–æ–º –∏ task_id.
        """
        print(f"\n[Executor] === –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Å—Ç–∞ ===")
        print(f"[Executor] –¢–µ–º–∞: '{topic}'")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–Ω–∞–ª –∏–∑ —Ç–µ–º—ã (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω) ‚Äî –∏—â–µ–º –∏ –ø–æ —Å–ª–æ–≤–∞–º –≤ –ø–∞–º—è—Ç–∏
        target_channel = self._extract_channel_from_topic(topic, user_id=user_id)
        if target_channel:
            print(f"[Executor] –¶–µ–ª–µ–≤–æ–π –∫–∞–Ω–∞–ª: {target_channel}")

        # –°–æ–±–∏—Ä–∞–µ–º SMM –∫–æ–Ω—Ç–µ–∫—Å—Ç (—Å —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ –∫–∞–Ω–∞–ª—É –∏–ª–∏ –ø–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –ø–æ —Ç–µ–º–µ)
        smm_context = self.build_smm_context(
            user_id,
            extra_style=style or "",
            target_channel=target_channel,
            topic=topic if not target_channel else None  # –ï—Å–ª–∏ –∫–∞–Ω–∞–ª —É–∫–∞–∑–∞–Ω —è–≤–Ω–æ ‚Äî –Ω–µ –∏—â–µ–º –ø–æ —Ç–µ–º–µ
        )

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω—É–∂–µ–Ω –ª–∏ web search
        skip_web_search = not self._needs_research(topic)

        # –°–æ–∑–¥–∞—ë–º –∑–∞–¥–∞—á—É
        task = self.tasks.enqueue(
            user_id=user_id,
            task_type="smm_generate",
            input_text=topic,
            input_data={
                "user_id": user_id,
                "topic": topic,
                "smm_context": smm_context,
                "skip_web_search": skip_web_search,
            }
        )

        print(f"[Executor] Task #{task.id} —Å–æ–∑–¥–∞–Ω")

        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –∑–∞–¥–∞—á—É –≤ running –∏ –∑–∞–ø—É—Å–∫–∞–µ–º Executor
        draft_text = ""
        try:
            # –ù–∞–ø—Ä—è–º—É—é –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ running (–±–µ–∑ claim –∏–∑ –æ–±—â–µ–π –æ—á–µ—Ä–µ–¥–∏)
            from datetime import datetime, timezone, timedelta
            now = datetime.now(timezone.utc)
            lease_expires = now + timedelta(seconds=300)

            self.db.execute(
                """UPDATE tasks
                   SET status = 'running', locked_by = ?, locked_at = ?,
                       lease_expires_at = ?, started_at = ?, updated_at = ?
                   WHERE id = ?""",
                ("smm_agent", now.isoformat(), lease_expires.isoformat(),
                 now.isoformat(), now.isoformat(), task.id)
            )

            running_task = self.tasks.get_task(task.id)
            if running_task:
                print(f"[Executor] Task #{task.id} running")
                self.executor.run_task(running_task)
        except ApprovalRequired as e:
            # –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π flow ‚Äî –∑–∞–¥–∞—á–∞ –æ—Å—Ç–∞–Ω–æ–≤–∏–ª–∞—Å—å –Ω–∞ APPROVAL
            draft_text = e.draft_content or ""
            print(f"[Executor] Task #{task.id} paused for approval")
        except Exception as e:
            print(f"[Executor] Error: {e}")
            import traceback
            traceback.print_exc()

        # –ï—Å–ª–∏ draft –ø—É—Å—Ç–æ–π ‚Äî –ø—Ä–æ–±—É–µ–º –¥–æ—Å—Ç–∞—Ç—å –∏–∑ task events
        if not draft_text:
            draft_text = self._get_draft_from_task(task.id)

        print(f"[Executor] === –ì–æ—Ç–æ–≤–æ ===\n")

        return PostDraft(
            text=draft_text,
            topic=topic,
            task_id=task.id,
            channel_id=self.get_channel_id(user_id) or ""
        )

    def _get_draft_from_task(self, task_id: int) -> str:
        """–ò–∑–≤–ª–µ—á—å draft –∏–∑ step_results –∑–∞–¥–∞—á–∏."""
        # –ò—â–µ–º –≤ task_events —Å–æ–±—ã—Ç–∏–µ —Å draft_content
        rows = self.db.fetch_all(
            """SELECT event_data FROM task_events
               WHERE task_id = ? AND event_type = 'paused'
               ORDER BY created_at DESC LIMIT 1""",
            (task_id,)
        )
        if rows:
            import json
            try:
                data = json.loads(rows[0][0])
                return data.get("draft_content", "")
            except:
                pass

        # Fallback: –∏—â–µ–º –≤ task_steps
        rows = self.db.fetch_all(
            """SELECT result FROM task_steps
               WHERE task_id = ? AND action = 'llm_call'
               ORDER BY step_index DESC LIMIT 1""",
            (task_id,)
        )
        if rows and rows[0][0]:
            import json
            try:
                data = json.loads(rows[0][0])
                return data.get("response", "")
            except:
                pass

        return ""

    def _needs_research(self, topic: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –Ω—É–∂–µ–Ω –ª–∏ –ø–æ–∏—Å–∫ –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."""
        topic_lower = topic.lower()

        years = re.findall(r'202[4-9]|203\d', topic)
        if years:
            return True

        keywords = [
            '—Ç—Ä–µ–Ω–¥', '–ø—Ä–æ–≥–Ω–æ–∑', '–Ω–æ–≤–æ—Å—Ç', '–∞–∫—Ç—É–∞–ª—å–Ω', '—Å–µ–π—á–∞—Å', '—Å–µ–≥–æ–¥–Ω—è',
            '–ø–æ—Å–ª–µ–¥–Ω', '—Å–≤–µ–∂–∏', '–Ω–µ–¥–∞–≤–Ω', '—ç—Ç–æ—Ç –≥–æ–¥', '–≤ —ç—Ç–æ–º –≥–æ–¥—É',
            '–∫—É—Ä—Å', '—Ü–µ–Ω–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å', '—Å–æ–±—ã—Ç–∏', '–Ω–æ–≤–∏–Ω–∫'
        ]

        return any(kw in topic_lower for kw in keywords)

    # ==================== –†–ï–î–ê–ö–¢–ò–†–û–í–ê–ù–ò–ï ====================

    def edit_post(self, user_id: int, original: str, edit_request: str, topic: str = "") -> str:
        """
        –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å—Ç (–≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥ v7).

        –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
        1. –†–∞–∑–±–∏–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ —á–∞—Å—Ç–∏
        2. –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º: precise (–∫–æ–¥) –∏–ª–∏ creative (LLM)
        3. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–∏–º–µ–Ω—è–µ–º –í–°–ï precise –æ–ø–µ—Ä–∞—Ü–∏–∏
        4. –ü–æ—Ç–æ–º creative (LLM –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç)
        """
        print(f"[Edit] –ó–∞–ø—Ä–æ—Å: {edit_request}")

        # 1. –†–∞–∑–±–∏–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ —á–∞—Å—Ç–∏
        parts = self._split_edit_request(edit_request)
        print(f"[Edit] –ß–∞—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–∞: {parts}")

        # 2. –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —á–∞—Å—Ç—å
        precise_parts = []
        creative_parts = []

        for part in parts:
            if self._is_precise_edit(part):
                precise_parts.append(part)
                print(f"[Edit]   precise: {part}")
            else:
                creative_parts.append(part)
                print(f"[Edit]   creative: {part}")

        # 3. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–∏–º–µ–Ω—è–µ–º –í–°–ï precise –æ–ø–µ—Ä–∞—Ü–∏–∏
        result = original
        for part in precise_parts:
            result = self._precise_edit(result, part)

        # 4. –ü–æ—Ç–æ–º creative (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if creative_parts:
            creative_request = ", ".join(creative_parts)
            result = self._creative_edit(user_id, result, creative_request, topic)

        # 5. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        result = re.sub(r'\n{3,}', '\n\n', result)
        result = re.sub(r'[ \t]+\n', '\n', result)
        # –£–±–∏—Ä–∞–µ–º –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ç–µ–≥–∏ (span, div, style –∏ —Ç.–¥.)
        result = re.sub(r'<span[^>]*>', '', result)
        result = re.sub(r'</span>', '', result)
        result = re.sub(r'<div[^>]*>', '', result)
        result = re.sub(r'</div>', '', result)
        result = result.strip()
        result = _markdown_to_html(result)

        self._save_edit_feedback(user_id, edit_request, original, result)
        return result

    def _split_edit_request(self, request: str) -> list:
        """–†–∞–∑–±–∏—Ç—å –∑–∞–ø—Ä–æ—Å –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã."""
        # –ó–∞—â–∏—â–∞–µ–º "N –∏ M" (—á–∏—Å–ª–∞) –æ—Ç —Ä–∞–∑–±–∏–µ–Ω–∏—è
        protected = re.sub(r'(\d+)\s+–∏\s+(\d+)', r'\1__AND__\2', request)

        # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏: "–∏", "–∞ —Ç–∞–∫–∂–µ", "–µ—â—ë", "–ø–ª—é—Å", –∑–∞–ø—è—Ç—ã–µ
        separators = r'\s+–∏\s+|\s+–∞\s+—Ç–∞–∫–∂–µ\s+|\s+–µ—â—ë\s+|\s+–µ—â–µ\s+|\s+—Ç–∞–∫–∂–µ\s+|\s+–ø–ª—é—Å\s+|,\s*'
        parts = re.split(separators, protected, flags=re.IGNORECASE)

        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º "N –∏ M"
        parts = [p.replace('__AND__', ' –∏ ') for p in parts]

        # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ –∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ
        parts = [p.strip() for p in parts if p and len(p.strip()) > 2]

        if not parts:
            return [request]

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç ‚Äî –µ—Å–ª–∏ –Ω–µ—Ç –≥–ª–∞–≥–æ–ª–∞, –±–µ—Ä—ë–º –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –∫–æ–º–∞–Ω–¥—ã
        result = []
        last_verb = "—É–±–µ—Ä–∏"
        verbs = ['–≤—ã–¥–µ–ª–∏', '—É–±–µ—Ä–∏', '—É–¥–∞–ª–∏', '–¥–æ–±–∞–≤—å', '–∑–∞–º–µ–Ω–∏', '—Å–¥–µ–ª–∞–π', '–ø–æ–º–µ–Ω—è–π', '–ø–µ—Ä–µ–ø–∏—à–∏', '–Ω–∞–ø–∏—à–∏', '—Ä–∞–∑–±–µ–π', '–∏–∑–º–µ–Ω–∏', '–∏—Å–ø—Ä–∞–≤—å', '—É–ª—É—á—à–∏', '–ø—Ä–æ–≤–µ—Ä—å', '–æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π']

        for part in parts:
            part_lower = part.lower()
            has_verb = any(v in part_lower for v in verbs)

            if has_verb:
                for v in verbs:
                    if v in part_lower:
                        last_verb = v
                        break
                result.append(part)
            else:
                # –ù–µ—Ç –≥–ª–∞–≥–æ–ª–∞ ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                result.append(f"{last_verb} {part}")

        return result if result else [request]

    def _is_precise_edit(self, request: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –º–æ–∂–Ω–æ –ª–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫–æ–¥–æ–º (–±–µ–∑ LLM)."""
        request_lower = request.lower()

        # "—á—ë—Ä–Ω—ã–º/—á–µ—Ä–Ω—ã–º" = "–∂–∏—Ä–Ω—ã–º" (–≥–æ–ª–æ—Å–æ–≤–æ–π –≤–≤–æ–¥)
        request_lower = request_lower.replace('—á—ë—Ä–Ω', '–∂–∏—Ä–Ω').replace('—á–µ—Ä–Ω', '–∂–∏—Ä–Ω')
        # "—Å–º–∞–π–ª–∏–∫–∏/—Å–º–∞–π–ª—ã" = "—ç–º–æ–¥–∑–∏"
        request_lower = re.sub(r'—Å–º–∞–π–ª–∏–∫\w*', '—ç–º–æ–¥–∑–∏', request_lower)
        request_lower = re.sub(r'—Å–º–∞–π–ª\w*', '—ç–º–æ–¥–∑–∏', request_lower)

        # –ù–∞–∑–≤–∞–Ω–∏—è —ç–º–æ–¥–∑–∏ (–¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è "—É–±–µ—Ä–∏ —Ä–∞–¥—É–≥—É" –±–µ–∑ —Å–ª–æ–≤–∞ "—ç–º–æ–¥–∑–∏")
        emoji_names_pattern = r'(—Ä–∞–¥—É–≥|—Å–æ–ª–Ω—Ü|—Å–µ—Ä–¥—Ü|—Å–µ—Ä–¥–µ—á|–æ–≥–æ–Ω|–æ–≥–æ–Ω—ë–∫|–∑–≤–µ–∑–¥|–∑–≤—ë–∑–¥|—Ü–≤–µ—Ç|—Ä–æ–∑|—Ä–∞–∫–µ—Ç|–º–æ–ª–Ω–∏|–¥–æ–º|–¥–æ–º–∏–∫|–∫–ª—é—á|–≥–∞–µ—á–Ω)'

        # –¢–æ—á–µ—á–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ ‚Äî –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        precise_patterns = [
            r'—É–±–µ—Ä–∏\s+—ç–º–æ–¥–∑–∏',
            r'—É–¥–∞–ª–∏\s+—ç–º–æ–¥–∑–∏',
            r'—É–±–µ—Ä–∏\s+–≤—Å–µ\s+—ç–º–æ–¥–∑–∏',
            r'–±–µ–∑\s+—ç–º–æ–¥–∑–∏',
            r'—É–±–µ—Ä–∏\s+.*' + emoji_names_pattern,  # "—É–±–µ—Ä–∏ —Ä–∞–¥—É–≥—É", "—É–±–µ—Ä–∏ —Ç–∞–º —ç—Ç—É —Ä–∞–¥—É–≥—É"
            r'—É–¥–∞–ª–∏\s+.*' + emoji_names_pattern,
            r'—É–±–µ—Ä–∏\s+(–ø–µ—Ä–≤—ã–π|–ø–æ—Å–ª–µ–¥–Ω–∏–π|–≤—Ç–æ—Ä–æ–π|—Ç—Ä–µ—Ç–∏–π|—á–µ—Ç–≤–µ—Ä—Ç—ã–π|—á–µ—Ç–≤—ë—Ä—Ç—ã–π|\d+[-]?–π?)\s*–∞–±–∑–∞—Ü',
            r'—É–¥–∞–ª–∏\s+(–ø–µ—Ä–≤—ã–π|–ø–æ—Å–ª–µ–¥–Ω–∏–π|–≤—Ç–æ—Ä–æ–π|—Ç—Ä–µ—Ç–∏–π|—á–µ—Ç–≤–µ—Ä—Ç—ã–π|—á–µ—Ç–≤—ë—Ä—Ç—ã–π|\d+[-]?–π?)\s*–∞–±–∑–∞—Ü',
            r'—É–±–µ—Ä–∏\s+–ø–æ—Å–ª–µ–¥–Ω–∏[–µ–π]\s+(–¥–≤–∞|—Ç—Ä–∏|—á–µ—Ç—ã—Ä–µ|\d+)\s*–∞–±–∑–∞—Ü',
            r'—É–¥–∞–ª–∏\s+–ø–æ—Å–ª–µ–¥–Ω–∏[–µ–π]\s+(–¥–≤–∞|—Ç—Ä–∏|—á–µ—Ç—ã—Ä–µ|\d+)\s*–∞–±–∑–∞—Ü',
            r'–≤—ã–¥–µ–ª–∏.*–∂–∏—Ä–Ω',
            r'—Å–¥–µ–ª–∞–π.*–∂–∏—Ä–Ω',
            r'—É–±–µ—Ä–∏\s+–∂–∏—Ä–Ω',
            r'–±–µ–∑\s+–∂–∏—Ä–Ω',
            r'—É–±–µ—Ä–∏\s+—Ö–µ—à—Ç–µ–≥',
            r'—É–±–µ—Ä–∏\s+—Ö—ç—à—Ç–µ–≥',
            r'—É–¥–∞–ª–∏\s+—Ö–µ—à—Ç–µ–≥',
            r'—É–¥–∞–ª–∏\s+—Ö—ç—à—Ç–µ–≥',
            r'–±–µ–∑\s+—Ö–µ—à—Ç–µ–≥',
            r'–±–µ–∑\s+—Ö—ç—à—Ç–µ–≥',
            r'–∑–∞–º–µ–Ω–∏\s+.+\s+–Ω–∞\s+',
            r'–≤–º–µ—Å—Ç–æ\s+.+\s+(–ø–æ—Å—Ç–∞–≤—å|—Å–¥–µ–ª–∞–π|–≤—Å—Ç–∞–≤—å)',
        ]

        for pattern in precise_patterns:
            if re.search(pattern, request_lower):
                return True

        return False

    def _precise_edit(self, text: str, request: str) -> str:
        """–ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ç–æ—á–µ—á–Ω—É—é –ø—Ä–∞–≤–∫—É –∫–æ–¥–æ–º (–±–µ–∑ LLM)."""
        result = text
        request_lower = request.lower()

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤—ã—Ö –∏—Å–∫–∞–∂–µ–Ω–∏–π
        request_lower = re.sub(r'—Å–º–∞–π–ª–∏–∫\w*', '—ç–º–æ–¥–∑–∏', request_lower)
        request_lower = re.sub(r'—Å–º–∞–π–ª\w*', '—ç–º–æ–¥–∑–∏', request_lower)

        # === –£–ë–ï–†–ò –≠–ú–û–î–ó–ò ===
        # –°–ª–æ–≤–∞—Ä—å —ç–º–æ–¥–∑–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—è–º
        emoji_names = {
            '—Ä–∞–¥—É–≥': 'üåà', '—Å–æ–ª–Ω—Ü': '‚òÄÔ∏è', '—Å–æ–ª–Ω—ã—à': 'üåû', '—Å–µ—Ä–¥—Ü': '‚ù§Ô∏è', '—Å–µ—Ä–¥–µ—á': 'üíñ',
            '–æ–≥–æ–Ω': 'üî•', '–æ–≥–æ–Ω—å': 'üî•', '–æ–≥–æ–Ω–µ–∫': 'üî•', '–æ–≥–æ–Ω—ë–∫': 'üî•',
            '–∑–≤–µ–∑–¥': '‚≠ê', '–∑–≤—ë–∑–¥': 'üåü', '—Ü–≤–µ—Ç': 'üå∏', '—Ä–æ–∑': 'üåπ',
            '—Ä–∞–∫–µ—Ç': 'üöÄ', '–º–æ–ª–Ω–∏': '‚ö°', '–≥–∞–ª–æ—á': '‚úÖ', '–∫—Ä–µ—Å—Ç': '‚ùå',
            '–≥–∞–µ—á–Ω': 'üîß', '–∫–ª—é—á': 'üîß', '–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç': 'üîß',
            '–¥–æ–º': 'üè†', '–¥–æ–º–∏–∫': 'üè†',
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ —É–±—Ä–∞—Ç—å —ç–º–æ–¥–∑–∏
        should_remove_emoji = (
            ('—ç–º–æ–¥–∑–∏' in request_lower or '—ç–º–æ–¥–∂–∏' in request_lower) or
            any(name in request_lower for name in emoji_names.keys())
        )

        if should_remove_emoji and ('—É–±–µ—Ä–∏' in request_lower or '—É–¥–∞–ª–∏' in request_lower or '–±–µ–∑' in request_lower):
            # –ò—â–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —ç–º–æ–¥–∑–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
            found_specific = False
            for name, emoji in emoji_names.items():
                if name in request_lower and emoji in result:
                    result = result.replace(emoji, '', 1)
                    print(f"[Edit] ‚úì precise: —É–±—Ä–∞–Ω —ç–º–æ–¥–∑–∏ {emoji}")
                    found_specific = True
                    break

            # –ò–ª–∏ —Å–∞–º —ç–º–æ–¥–∑–∏ –≤ –∑–∞–ø—Ä–æ—Å–µ
            if not found_specific:
                emoji_pattern = re.compile("[\U0001F300-\U0001F9FF\u2600-\u26FF\u2700-\u27BF]+")
                emojis_in_request = emoji_pattern.findall(request)
                for em in emojis_in_request:
                    if em in result:
                        result = result.replace(em, '', 1)
                        print(f"[Edit] ‚úì precise: —É–±—Ä–∞–Ω —ç–º–æ–¥–∑–∏ {em}")
                        found_specific = True

            # –ò–ª–∏ —É–±—Ä–∞—Ç—å –í–°–ï —ç–º–æ–¥–∑–∏ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —è–≤–Ω–æ —Å–∫–∞–∑–∞–ª–∏ "—ç–º–æ–¥–∑–∏" –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏)
            if not found_specific and ('—ç–º–æ–¥–∑–∏' in request_lower or '—ç–º–æ–¥–∂–∏' in request_lower):
                emoji_pattern = re.compile("[\U0001F300-\U0001F9FF\u2600-\u26FF\u2700-\u27BF]+")
                result = emoji_pattern.sub('', result)
                print(f"[Edit] ‚úì precise: —É–±—Ä–∞–Ω—ã –≤—Å–µ —ç–º–æ–¥–∑–∏")

        # === –£–ë–ï–†–ò –ê–ë–ó–ê–¶ ===
        paragraphs = [p for p in result.split('\n\n') if p.strip()]

        # –ü–æ—Å–ª–µ–¥–Ω–∏–π –∞–±–∑–∞—Ü
        if re.search(r'(—É–±–µ—Ä–∏|—É–¥–∞–ª–∏).*–ø–æ—Å–ª–µ–¥–Ω\w*\s*–∞–±–∑–∞—Ü', request_lower):
            if len(paragraphs) > 1:
                result = '\n\n'.join(paragraphs[:-1])
                print(f"[Edit] ‚úì precise: —É–¥–∞–ª—ë–Ω –ø–æ—Å–ª–µ–¥–Ω–∏–π –∞–±–∑–∞—Ü")

        # –ü–æ—Å–ª–µ–¥–Ω–∏–µ N –∞–±–∑–∞—Ü–µ–≤
        last_n_match = re.search(r'(—É–±–µ—Ä–∏|—É–¥–∞–ª–∏).*–ø–æ—Å–ª–µ–¥–Ω–∏[–µ—Ö]\s+(–¥–≤–∞|—Ç—Ä–∏|—á–µ—Ç—ã—Ä–µ|\d+)\s*–∞–±–∑–∞—Ü', request_lower)
        if last_n_match:
            num_word = last_n_match.group(2)
            num_map = {'–¥–≤–∞': 2, '—Ç—Ä–∏': 3, '—á–µ—Ç—ã—Ä–µ': 4}
            n = num_map.get(num_word, int(num_word) if num_word.isdigit() else 1)
            paragraphs = [p for p in result.split('\n\n') if p.strip()]
            if len(paragraphs) > n:
                result = '\n\n'.join(paragraphs[:-n])
                print(f"[Edit] ‚úì precise: —É–¥–∞–ª–µ–Ω—ã –ø–æ—Å–ª–µ–¥–Ω–∏–µ {n} –∞–±–∑–∞—Ü–µ–≤")

        # –ü–µ—Ä–≤—ã–π –∞–±–∑–∞—Ü
        if re.search(r'(—É–±–µ—Ä–∏|—É–¥–∞–ª–∏).*–ø–µ—Ä–≤\w*\s*–∞–±–∑–∞—Ü', request_lower):
            paragraphs = [p for p in result.split('\n\n') if p.strip()]
            if len(paragraphs) > 1:
                result = '\n\n'.join(paragraphs[1:])
                print(f"[Edit] ‚úì precise: —É–¥–∞–ª—ë–Ω –ø–µ—Ä–≤—ã–π –∞–±–∑–∞—Ü")

        # N-—ã–π –∞–±–∑–∞—Ü (–≤—Ç–æ—Ä–æ–π, —Ç—Ä–µ—Ç–∏–π, —á–µ—Ç–≤–µ—Ä—Ç—ã–π)
        ordinals = {'–≤—Ç–æ—Ä': 2, '—Ç—Ä–µ—Ç': 3, '—á–µ—Ç–≤–µ—Ä—Ç': 4, '—á–µ—Ç–≤—ë—Ä—Ç': 4, '–ø—è—Ç': 5}
        for ordinal, idx in ordinals.items():
            if ordinal in request_lower and '–∞–±–∑–∞—Ü' in request_lower:
                if '—É–±–µ—Ä–∏' in request_lower or '—É–¥–∞–ª–∏' in request_lower:
                    paragraphs = [p for p in result.split('\n\n') if p.strip()]
                    if idx <= len(paragraphs):
                        paragraphs.pop(idx - 1)
                        result = '\n\n'.join(paragraphs)
                        print(f"[Edit] ‚úì precise: —É–¥–∞–ª—ë–Ω {idx}-–π –∞–±–∑–∞—Ü")
                    break

        # === –í–´–î–ï–õ–ò –ñ–ò–†–ù–´–ú ===
        # "—á—ë—Ä–Ω—ã–º" = "–∂–∏—Ä–Ω—ã–º" (–≥–æ–ª–æ—Å–æ–≤–æ–π –≤–≤–æ–¥)
        bold_request = request_lower.replace('—á–µ—Ä–Ω', '–∂–∏—Ä–Ω').replace('—á—ë—Ä–Ω', '–∂–∏—Ä–Ω')

        if re.search(r'(–≤—ã–¥–µ–ª–∏|—Å–¥–µ–ª–∞–π).*–∂–∏—Ä–Ω', bold_request):
            # –í—ã–¥–µ–ª–∏—Ç—å –ø–µ—Ä–≤—ã–π –∞–±–∑–∞—Ü
            if re.search(r'–ø–µ—Ä–≤\w*\s*–∞–±–∑–∞—Ü', bold_request):
                paragraphs = result.split('\n\n')
                if paragraphs and '<b>' not in paragraphs[0]:
                    paragraphs[0] = f'<b>{paragraphs[0]}</b>'
                    result = '\n\n'.join(paragraphs)
                    print(f"[Edit] ‚úì precise: –ø–µ—Ä–≤—ã–π –∞–±–∑–∞—Ü –∂–∏—Ä–Ω—ã–º")

            # –í—ã–¥–µ–ª–∏—Ç—å –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
            elif re.search(r'–ø–µ—Ä–≤\w*\s*–ø—Ä–µ–¥–ª–æ–∂', bold_request):
                sentences = re.split(r'(?<=[.!?])\s+', result, maxsplit=1)
                if sentences and '<b>' not in sentences[0]:
                    result = f'<b>{sentences[0]}</b>'
                    if len(sentences) > 1:
                        result += '\n\n' + sentences[1]
                    print(f"[Edit] ‚úì precise: –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∂–∏—Ä–Ω—ã–º")

            # –í—ã–¥–µ–ª–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é —Ñ—Ä–∞–∑—É (—á–∏—Å–ª–æ, –ø—Ä–æ—Ü–µ–Ω—Ç)
            else:
                # –ò—â–µ–º —á—Ç–æ –≤—ã–¥–µ–ª–∏—Ç—å –≤ –∑–∞–ø—Ä–æ—Å–µ
                phrase_match = re.search(r'–≤—ã–¥–µ–ª\w*\s+([^\s]+(?:\s+[^\s]+)?)\s+–∂–∏—Ä–Ω', request_lower)
                if not phrase_match:
                    phrase_match = re.search(r'(\d+%?)', request)
                if phrase_match:
                    phrase = phrase_match.group(1).strip()
                    if phrase in result and f'<b>{phrase}</b>' not in result:
                        result = result.replace(phrase, f'<b>{phrase}</b>', 1)
                        print(f"[Edit] ‚úì precise: –≤—ã–¥–µ–ª–µ–Ω–æ –∂–∏—Ä–Ω—ã–º: {phrase}")

        # === –£–ë–ï–†–ò –ñ–ò–†–ù–´–ô ===
        if re.search(r'(—É–±–µ—Ä–∏|–±–µ–∑)\s*–∂–∏—Ä–Ω', request_lower):
            if '<b>' in result or '**' in result:
                result = re.sub(r'</?b>', '', result)
                result = re.sub(r'\*\*([^*]+)\*\*', r'\1', result)
                print(f"[Edit] ‚úì precise: —É–±—Ä–∞–Ω –∂–∏—Ä–Ω—ã–π")
            else:
                print(f"[Edit] ‚Ñπ precise: –∂–∏—Ä–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç")

        # === –£–ë–ï–†–ò –•–ï–®–¢–ï–ì–ò ===
        if re.search(r'(—É–±–µ—Ä–∏|—É–¥–∞–ª–∏|–±–µ–∑)\s*(—Ö–µ—à—Ç–µ–≥|—Ö—ç—à—Ç–µ–≥)', request_lower):
            if '#' in result:
                result = re.sub(r'#\w+\s*', '', result)
                print(f"[Edit] ‚úì precise: —É–±—Ä–∞–Ω—ã —Ö–µ—à—Ç–µ–≥–∏")
            else:
                print(f"[Edit] ‚Ñπ precise: —Ö–µ—à—Ç–µ–≥–æ–≤ –Ω–µ—Ç")

        # === –ó–ê–ú–ï–ù–ê ===
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã: "–∑–∞–º–µ–Ω–∏ X –Ω–∞ Y", "–≤–º–µ—Å—Ç–æ X –ø–æ—Å—Ç–∞–≤—å Y", "X –∑–∞–º–µ–Ω–∏ –Ω–∞ Y"
        replace_match = re.search(r'–∑–∞–º–µ–Ω–∏\s+(.+?)\s+–Ω–∞\s+(.+?)(?:\s*$|\s*,)', request, re.IGNORECASE)
        if not replace_match:
            replace_match = re.search(r'–≤–º–µ—Å—Ç–æ\s+(.+?)\s+(?:–ø–æ—Å—Ç–∞–≤—å|—Å–¥–µ–ª–∞–π|–≤—Å—Ç–∞–≤—å)\s+(.+?)(?:\s*$|\s*,)', request, re.IGNORECASE)

        if replace_match:
            old_text, new_text = replace_match.group(1).strip(), replace_match.group(2).strip()

            # –ï—Å–ª–∏ —ç—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏—è —ç–º–æ–¥–∑–∏ ‚Äî –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —ç–º–æ–¥–∑–∏
            emoji_map = {
                '—Å–µ—Ä–¥–µ—á–∫': 'üíñ', '—Å–µ—Ä–¥—Ü': '‚ù§Ô∏è', '–æ–≥–æ–Ω–µ–∫': 'üî•', '–æ–≥–æ–Ω—ë–∫': 'üî•', '–æ–≥–æ–Ω': 'üî•',
                '–∑–≤–µ–∑–¥': '‚≠ê', '–∑–≤—ë–∑–¥': 'üåü', '—Å–æ–ª–Ω—Ü': '‚òÄÔ∏è', '—Ä–∞–¥—É–≥': 'üåà',
                '—Ü–≤–µ—Ç–æ—á–µ–∫': 'üå∏', '—Ü–≤–µ—Ç': 'üå∏', '—Ä–æ–∑': 'üåπ', '—Ä–∞–∫–µ—Ç': 'üöÄ',
            }

            # –ò—â–µ–º —ç–º–æ–¥–∑–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –¥–ª—è old
            for name, emoji in emoji_map.items():
                if name in old_text.lower():
                    # –ò—â–µ–º –ª—é–±–æ–π —ç–º–æ–¥–∑–∏-—Å–µ—Ä–¥—Ü–µ/–æ–≥–æ–Ω—å –∏ —Ç.–ø. –≤ —Ç–µ–∫—Å—Ç–µ
                    if name.startswith('—Å–µ—Ä–¥—Ü') or name.startswith('—Å–µ—Ä–¥–µ—á'):
                        for em in ['üíñ', '‚ù§Ô∏è', 'üíï', 'üíó', 'üíì', 'üíò', 'ü©∑', 'üß°', 'üíõ', 'üíö', 'üíô', 'üíú', 'üñ§', 'ü§ç', 'ü§é']:
                            if em in result:
                                old_text = em
                                break
                    elif emoji in result:
                        old_text = emoji
                    break

            # –ò—â–µ–º —ç–º–æ–¥–∑–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –¥–ª—è new
            for name, emoji in emoji_map.items():
                if name in new_text.lower():
                    new_text = emoji
                    break

            if old_text in result:
                result = result.replace(old_text, new_text, 1)
                print(f"[Edit] ‚úì precise: –∑–∞–º–µ–Ω–µ–Ω–æ '{old_text}' ‚Üí '{new_text}'")

        return result

    def _creative_edit(self, user_id: int, original: str, request: str, topic: str) -> str:
        """LLM —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞–ø—Ä—è–º—É—é (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç)."""

        # –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å—Ç–∏–ª—è –∏–∑ –ø–∞–º—è—Ç–∏
        style_hint = ""
        if topic:
            try:
                results = self.memory.search(user_id, f"—Å—Ç–∏–ª—å {topic}", limit=1)
                if results:
                    style_hint = f"\n\n–°–¢–ò–õ–¨ –ö–õ–ò–ï–ù–¢–ê: {results[0].content[:200]}"
            except:
                pass

        # –ù—É–º–µ—Ä—É–µ–º –∞–±–∑–∞—Ü—ã –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        paragraphs = [p.strip() for p in original.split('\n\n') if p.strip()]
        numbered = "\n\n".join([f"[–ê–±–∑–∞—Ü {i+1}] {p}" for i, p in enumerate(paragraphs)])

        prompt = f"""–¢–ï–ö–°–¢ –ü–û–°–¢–ê ({len(paragraphs)} –∞–±–∑–∞—Ü–µ–≤):
{numbered}

–ó–ê–ü–†–û–°: {request}{style_hint}

–ü–†–ê–í–ò–õ–ê:
- –†–∞–±–æ—Ç–∞–π –¢–û–õ–¨–ö–û —Å —Ç–µ–∫—Å—Ç–æ–º –≤—ã—à–µ ‚Äî –æ–Ω —É–∂–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –∏–∑–º–µ–Ω—ë–Ω
- –ù–ï –¥–æ–±–∞–≤–ª—è–π –∞–±–∑–∞—Ü—ã –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ
- –ù–ï –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–π —É–¥–∞–ª—ë–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
- "–¥–æ–±–∞–≤—å —Ö—É–∫" = —Ü–µ–ø–ª—è—é—â–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –í –ù–ê–ß–ê–õ–û –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–π –∞–±–∑–∞—Ü
- –°–æ—Ö—Ä–∞–Ω–∏ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã (–¥–∞—Ç—ã, —Ü–∏—Ñ—Ä—ã, —É—Å–ª–æ–≤–∏—è)
- –°—Ç–∏–ª—å –∏ —Ç–æ–Ω ‚Äî –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ
- –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ç–µ–≥–∏ <b> –¥–ª—è –∂–∏—Ä–Ω–æ–≥–æ
- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π span, div, style –∏–ª–∏ –¥—Ä—É–≥–∏–µ HTML —Ç–µ–≥–∏

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≥–æ—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞ –ë–ï–ó –Ω—É–º–µ—Ä–∞—Ü–∏–∏ –∞–±–∑–∞—Ü–µ–≤, –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤."""

        print(f"[Edit] Creative mode: {request}")
        response = self.llm.complete_simple(prompt)
        result = response.strip()

        # –£–±–∏—Ä–∞–µ–º markdown –æ–±—ë—Ä—Ç–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        if result.startswith("```"):
            result = re.sub(r'^```\w*\s*', '', result)
            result = re.sub(r'\s*```$', '', result)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–¥–µ–∫–≤–∞—Ç–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        request_lower = request.lower()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–∂–∏–¥–∞–µ–º—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã –¥–ª–∏–Ω—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞
        expand_words = ['–¥–æ–±–∞–≤—å', '–¥–æ–ø–æ–ª–Ω–∏', '—Ä–∞—Å—à–∏—Ä—å', '–Ω–∞–ø–∏—à–∏ –µ—â—ë', '–Ω–∞–ø–∏—à–∏ –µ—â–µ',
                        '–±–æ–ª—å—à–µ', '–¥–ª–∏–Ω–Ω–µ–µ', '–ø–æ–¥—Ä–æ–±–Ω–µ–µ', '—Ä–∞–∑–≤–µ—Ä–Ω–∏', '—É–≤–µ–ª–∏—á—å']
        if any(word in request_lower for word in expand_words):
            # –ó–∞–ø—Ä–æ—Å –Ω–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ - —Ä–∞–∑—Ä–µ—à–∞–µ–º –¥–æ 5x
            max_multiplier = 5
            min_multiplier = 0.8  # –ù–µ –¥–æ–ª–∂–µ–Ω —Å–∏–ª—å–Ω–æ —Å–æ–∫—Ä–∞—â–∞—Ç—å –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏
        elif any(word in request_lower for word in ['—Å–æ–∫—Ä–∞—Ç–∏', '–∫–æ—Ä–æ—á–µ', '—É–±–µ—Ä–∏', '—É–¥–∞–ª–∏']):
            # –ó–∞–ø—Ä–æ—Å –Ω–∞ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ - —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ—Ä–æ—á–µ –∏–ª–∏ —Ä–∞–≤–µ–Ω
            max_multiplier = 1.2  # –ù–µ–±–æ–ª—å—à–æ–π –∑–∞–ø–∞—Å –Ω–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            min_multiplier = 0.1
        else:
            # –û–±—ã—á–Ω–æ–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            max_multiplier = 3
            min_multiplier = 0.3

        min_len = max(20, int(len(original) * min_multiplier))
        max_len = int(len(original) * max_multiplier)

        if len(result) < min_len or len(result) > max_len:
            print(f"[Edit] Creative –≤–µ—Ä–Ω—É–ª —Å—Ç—Ä–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (len={len(result)}, expected {min_len}-{max_len}), –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª")
            return original

        print(f"[Edit] ‚úì creative edit done")
        return result

    def _save_edit_feedback(self, user_id: int, edit_request: str, original: str, edited: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∏–¥–±–µ–∫ –æ –ø—Ä–∞–≤–∫–µ."""
        self.save_feedback(user_id, f"–ü—Ä–∞–≤–∫–∞: {edit_request}", original)
        self.memory.store(
            user_id=user_id,
            content=f"–ü—Ä–∏–º–µ—Ä –ø—Ä–∞–≤–∫–∏: '{edit_request}' | –ë—ã–ª–æ: {original[:150]}... | –°—Ç–∞–ª–æ: {edited[:150]}...",
            memory_type=MemoryType.FEEDBACK,
            importance=0.85
        )

    def edit_post_with_history(self, user_id: int, current: str, edit_request: str, versions: list) -> str:
        """–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å—Ç —Å —É—á—ë—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏ –≤–µ—Ä—Å–∏–π."""
        history_context = ""
        if len(versions) > 1:
            history_context = f"\n\n–ò–°–¢–û–†–ò–Ø –í–ï–†–°–ò–ô:\n- –û—Ä–∏–≥–∏–Ω–∞–ª: {versions[0][:200]}..."
            if len(versions) > 2:
                history_context += f"\n- –ü—Ä–µ–¥—ã–¥—É—â–∞—è –≤–µ—Ä—Å–∏—è: {versions[-2][:200]}..."

        prompt = f"""–¢–µ–∫—É—â–∏–π —Ç–µ–∫—Å—Ç:
{current}
{history_context}

–ó–∞–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞: {edit_request}

–í–ê–ñ–ù–û:
- –ï—Å–ª–∏ –ø—Ä–æ—Å—è—Ç "–≤–µ—Ä–Ω–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª/–ø–µ—Ä–≤—ã–π –≤–∞—Ä–∏–∞–Ω—Ç" ‚Äî –≤–µ—Ä–Ω–∏ –û–†–ò–ì–ò–ù–ê–õ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏
- –ï—Å–ª–∏ –ø—Ä–æ—Å—è—Ç "–æ—Ç–∫–∞—Ç–∏/–Ω–∞–∑–∞–¥" ‚Äî –≤–µ—Ä–Ω–∏ –ü–†–ï–î–´–î–£–©–£–Æ –≤–µ—Ä—Å–∏—é
- –ò–Ω–∞—á–µ ‚Äî –≤–Ω–µ—Å–∏ –ø—Ä–∞–≤–∫—É –≤ —Ç–µ–∫—É—â–∏–π —Ç–µ–∫—Å—Ç
- –í–æ–∑–≤—Ä–∞—â–∞–π –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞, –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤"""

        response = self.llm.complete(
            messages=[
                Message.system("–¢—ã —Ä–µ–¥–∞–∫—Ç–æ—Ä. –ü–æ–Ω–∏–º–∞–µ—à—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–∞–≤–æ–∫."),
                Message.user(prompt)
            ],
            user_id=user_id
        )

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º markdown ‚Üí HTML
        edited = _markdown_to_html(response.content)
        self.save_feedback(user_id, f"–ü—Ä–∞–≤–∫–∞: {edit_request}", current)

        return edited

    def approve_post(self, task_id: int, user_id: int, post_text: str):
        """–û–¥–æ–±—Ä–∏—Ç—å –ø–æ—Å—Ç."""
        self.tasks.succeed(task_id, result={"text": post_text})
        self.save_successful_post(user_id, post_text)

    def reject_post(self, task_id: int, user_id: int, reason: str = ""):
        """–û—Ç–∫–ª–æ–Ω–∏—Ç—å –ø–æ—Å—Ç."""
        self.tasks.fail(task_id, error=reason or "rejected")
        if reason:
            self.save_feedback(user_id, f"–û—Ç–∫–ª–æ–Ω–µ–Ω–æ: {reason}")

    # ==================== –ê–ù–ê–õ–ò–ó –ö–û–ù–ö–£–†–ï–ù–¢–û–í ====================

    def _is_ad_post(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–µ–∫–ª–∞–º–Ω—ã–π –ø–æ—Å—Ç."""
        ad_markers = [
            '#—Ä–µ–∫–ª–∞–º–∞', '#ad', '#–ø—Ä–æ–º–æ', '#promo', '—Ä–µ–∫–ª–∞–º–∞',
            '–ø–µ—Ä–µ—Ö–æ–¥–∏ –ø–æ —Å—Å—ã–ª–∫–µ', '–∫—É–ø–∏—Ç—å', '—Å–∫–∏–¥–∫–∞', '–ø—Ä–æ–º–æ–∫–æ–¥',
            '–∑–∞–∫–∞–∂–∏', '–æ–ø–ª–∞—Ç–∏', '–ø–æ–¥–ø–∏—Å—ã–≤–∞–π—Å—è', '—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Å—è'
        ]
        text_lower = text.lower()
        return any(marker in text_lower for marker in ad_markers)

    def analyze_single_channel(self, user_id: int, channel: str) -> tuple:
        """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (raw_posts, analysis)."""
        try:
            posts = self.parser.get_top_posts(channel, limit=20)
            organic_posts = [p for p in posts if not self._is_ad_post(p.text)][:15]

            if not organic_posts:
                return "", f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –æ—Ä–≥–∞–Ω–∏—á–µ—Å–∫–∏—Ö –ø–æ—Å—Ç–æ–≤ –≤ {channel}"

            posts_list = []
            for p in organic_posts:
                posts_list.append(f"üëÅ {p.views}: {p.text[:200]}...")

            posts_text = "\n\n".join(posts_list)

            prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–æ–ø–æ–≤—ã–µ –ø–æ—Å—Ç—ã –∫–∞–Ω–∞–ª–∞ {channel}.

–ü–û–°–¢–´ (–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞–º):
{posts_text}

–í—ã–¥–µ–ª–∏:
1. –ö–∞–∫–∏–µ —Ç–µ–º—ã –∑–∞—Ö–æ–¥—è—Ç –ª—É—á—à–µ –≤—Å–µ–≥–æ
2. –°—Ç–∏–ª—å –Ω–∞–ø–∏—Å–∞–Ω–∏—è (–¥–ª–∏–Ω–∞, —Ç–æ–Ω, —ç–º–æ–¥–∑–∏)
3. –ß—Ç–æ –¥–µ–ª–∞–µ—Ç —ç—Ç–∏ –ø–æ—Å—Ç—ã –ø–æ–ø—É–ª—è—Ä–Ω—ã–º–∏
4. 2-3 –∏–¥–µ–∏ –¥–ª—è –ø–æ—Ö–æ–∂–∏—Ö –ø–æ—Å—Ç–æ–≤

–ö—Ä–∞—Ç–∫–æ, –ø–æ –ø—É–Ω–∫—Ç–∞–º."""

            response = self.llm.complete(
                messages=[
                    Message.system("–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –∫–æ–Ω—Ç–µ–Ω—Ç–∞."),
                    Message.user(prompt)
                ],
                user_id=user_id
            )

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º markdown ‚Üí HTML
            analysis = _markdown_to_html(response.content)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ (—É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)
            self.memory.store(
                user_id=user_id,
                content=f"–°—Ç–∏–ª—å –∫–∞–Ω–∞–ª–∞ {channel}: {analysis[:1500]}",
                memory_type=MemoryType.CONTEXT,
                importance=0.85,
                metadata={"channel": channel, "analysis_version": "v1"}
            )

            return posts_text, analysis

        except Exception as e:
            return "", f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {channel}: {e}"

    def analyze_competitors(self, user_id: int) -> tuple:
        """–ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤."""
        competitors = self.get_competitors(user_id)
        if not competitors:
            return "", "–ù–µ—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤. –î–æ–±–∞–≤—å —á–µ—Ä–µ–∑ /competitor @channel"

        all_results = []
        all_posts = []

        for channel in competitors[:5]:
            posts_text, analysis = self.analyze_single_channel(user_id, channel)
            if posts_text:
                all_posts.append(f"=== {channel} ===\n{posts_text}")
                all_results.append(f"=== {channel} ===\n{analysis}")

        if not all_results:
            return "", "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–∞–Ω–∞–ª—ã"

        return "\n\n".join(all_posts), "\n\n".join(all_results)

    # –ê–ª–∏–∞—Å –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    def _silent_analyze(self, user_id: int, channel: str):
        """–¢–∏—Ö–∏–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Executor."""
        self._analyze_channel_via_executor(user_id, channel)

    # ==================== –ò–î–ï–ò ====================

    def propose_ideas(self, user_id: int) -> str:
        """
        –ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å –∏–¥–µ–∏ –¥–ª—è –ø–æ—Å—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ:
        1. –°—Ç–∏–ª—è –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        2. –°–≤–µ–∂–∏—Ö —Ç–æ–ø-–ø–æ—Å—Ç–æ–≤ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
        3. –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤
        """
        context = self.build_smm_context(user_id)

        # –°–≤–µ–∂–∏–µ —Ç–æ–ø-–ø–æ—Å—Ç—ã –æ—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
        competitors = self.get_competitors(user_id)
        trending_posts = []
        if competitors:
            for channel in competitors[:3]:
                try:
                    posts = self.parser.get_top_posts(channel, limit=5)
                    for p in posts[:3]:
                        if not self._is_ad_post(p.text):
                            trending_posts.append(f"[{channel}] üëÅ{p.views}: {p.text[:120]}...")
                except Exception:
                    continue

        trending_text = "\n".join(trending_posts) if trending_posts else ""

        # –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã –∏–∑ –ø–∞–º—è—Ç–∏
        trends_items = self.db.fetch_all(
            """SELECT content FROM memory_items
               WHERE user_id = ? AND content LIKE '–¢—Ä–µ–Ω–¥:%'
               ORDER BY created_at DESC LIMIT 3""",
            (user_id,)
        )
        saved_trends = "\n".join([t[0] for t in trends_items]) if trends_items else ""

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        analysis_parts = []
        if trending_text:
            analysis_parts.append(f"–°–í–ï–ñ–ò–ï –¢–û–ü–´ –ö–û–ù–ö–£–†–ï–ù–¢–û–í:\n{trending_text}")
        if saved_trends:
            analysis_parts.append(f"–¢–†–ï–ù–î–´ –ò–ó –ê–ù–ê–õ–ò–ó–ê:\n{saved_trends}")

        if not analysis_parts:
            return (
                "üì≠ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–¥–µ–π.\n\n"
                "–î–æ–±–∞–≤—å—Ç–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤: /competitor @channel\n"
                "–ò–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –∞–Ω–∞–ª–∏–∑: /analyze"
            )

        prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–∏ 3-5 –∏–¥–µ–π –¥–ª—è –ø–æ—Å—Ç–æ–≤.

–ö–û–ù–¢–ï–ö–°–¢ –ö–õ–ò–ï–ù–¢–ê:
{context}

{chr(10).join(analysis_parts)}

–î–ª—è –∫–∞–∂–¥–æ–π –∏–¥–µ–∏:
1. <b>–¢–µ–º–∞</b>: —Ü–µ–ø–ª—è—é—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
2. <b>–ü–æ—á–µ–º—É –∑–∞–π–¥—ë—Ç</b>: 1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
3. <b>–§–æ—Ä–º–∞—Ç</b>: –∫–æ—Ä–æ—Ç–∫–∏–π/–¥–ª–∏–Ω–Ω—ã–π, —Ç–æ–Ω

–í—ã–±–∏—Ä–∞–π —Ç–µ–º—ã –∫–æ—Ç–æ—Ä—ã–µ –£–ñ–ï —Ä–∞–±–æ—Ç–∞—é—Ç —É –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤."""

        response = self.llm.complete(
            messages=[
                Message.system("–¢—ã SMM-—ç–∫—Å–ø–µ—Ä—Ç. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å —É—Å–ø–µ—à–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—à—å –∏–¥–µ–∏."),
                Message.user(prompt)
            ],
            user_id=user_id
        )

        return _markdown_to_html(response.content)

    # ==================== –û–¢–ß–Å–¢–´ ====================

    def weekly_report(self, user_id: int) -> str:
        """–ù–µ–¥–µ–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç."""
        week_ago = (datetime.now() - timedelta(days=7)).isoformat()

        posts = self.db.fetch_all(
            """SELECT content FROM memory_items
               WHERE user_id = ? AND content LIKE '–£–¥–∞—á–Ω—ã–π –ø–æ—Å—Ç:%'
               AND created_at > ?""",
            (user_id, week_ago)
        )

        posts_text = "\n".join([p[0] for p in posts]) if posts else "–ù–µ—Ç –ø–æ—Å—Ç–æ–≤ –∑–∞ –Ω–µ–¥–µ–ª—é"

        prompt = f"""–°–æ—Å—Ç–∞–≤—å –Ω–µ–¥–µ–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç –ø–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É.

–û–ü–£–ë–õ–ò–ö–û–í–ê–ù–ù–´–ï –ü–û–°–¢–´:
{posts_text}

–ú–ï–¢–†–ò–ö–ò:
–ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã

–ù–∞–ø–∏—à–∏:
1. –ß—Ç–æ –∑–∞—à–ª–æ –ª—É—á—à–µ –≤—Å–µ–≥–æ
2. –ß—Ç–æ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ
3. 2-3 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –Ω–µ–¥–µ–ª—é

–ö—Ä–∞—Ç–∫–æ, –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ, —Å —Ü–∏—Ñ—Ä–∞–º–∏."""

        response = self.llm.complete(
            messages=[
                Message.system("–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –∫–æ–Ω—Ç–µ–Ω—Ç–∞."),
                Message.user(prompt)
            ],
            user_id=user_id
        )

        return _markdown_to_html(response.content)

    # ==================== –ù–û–í–û–°–¢–ò –ò –ü–û–ò–°–ö ====================

    def fetch_hot_news(self, user_id: int) -> tuple:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≥–æ—Ä—è—á–∏–µ —Ç–µ–º—ã –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
        1. –î–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ RSS-–∏—Å—Ç–æ—á–Ω–∏–∫–∏
        2. –¢—Ä–µ–Ω–¥—ã –∏–∑ –∫–∞–Ω–∞–ª–æ–≤ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤

        –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ tech-—Å–∞–π—Ç—ã!
        """
        content_parts = []

        # 1. RSS-–∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_sources = self.get_news_sources(user_id)
        if user_sources:
            news_items = []
            for src in user_sources[:5]:
                items = self.news.fetch_custom_rss(src["url"], src["name"], limit=3)
                news_items.extend(items)

            if news_items:
                news_text = []
                for n in news_items[:10]:
                    news_text.append(f"[{n.source}] {n.title}\n{n.summary[:150]}...")
                content_parts.append("–ù–û–í–û–°–¢–ò –ò–ó –í–ê–®–ò–• –ò–°–¢–û–ß–ù–ò–ö–û–í:\n" + "\n\n".join(news_text))

        # 2. –¢—Ä–µ–Ω–¥—ã –∏–∑ –∫–∞–Ω–∞–ª–æ–≤ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ (—Ç–æ–ø –ø–æ—Å—Ç—ã)
        competitors = self.get_competitors(user_id)
        if competitors:
            trending_posts = []
            for channel in competitors[:3]:
                try:
                    posts = self.parser.get_top_posts(channel, limit=3)
                    for p in posts[:2]:
                        if not self._is_ad_post(p.text):
                            trending_posts.append(f"[{channel}] üëÅ{p.views}: {p.text[:150]}...")
                except Exception:
                    continue

            if trending_posts:
                content_parts.append("–ü–û–ü–£–õ–Ø–†–ù–û–ï –£ –ö–û–ù–ö–£–†–ï–ù–¢–û–í:\n" + "\n\n".join(trending_posts))

        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ—Ç ‚Äî –ø–æ–¥—Å–∫–∞–∂–µ–º —á—Ç–æ –¥–æ–±–∞–≤–∏—Ç—å
        if not content_parts:
            return "", (
                "üì≠ –ù–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.\n\n"
                "–î–æ–±–∞–≤—å—Ç–µ:\n"
                "‚Ä¢ –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤: /competitor @channel\n"
                "‚Ä¢ RSS-–∏—Å—Ç–æ—á–Ω–∏–∫–∏: /source"
            )

        raw_content = "\n\n---\n\n".join(content_parts)

        prompt = f"""–í–æ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:

{raw_content}

–ó–ê–î–ê–ß–ê: –ü—Ä–µ–¥–ª–æ–∂–∏ 3-5 –∏–¥–µ–π –¥–ª—è –ø–æ—Å—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö.

–î–ª—è –∫–∞–∂–¥–æ–π –∏–¥–µ–∏:
1. <b>–¢–µ–º–∞ –ø–æ—Å—Ç–∞</b>: —Ü–µ–ø–ª—è—é—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
2. <b>–°—É—Ç—å</b>: –æ —á—ë–º –ø–æ—Å—Ç (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
3. <b>–ü–æ—á–µ–º—É –∞–∫—Ç—É–∞–ª—å–Ω–æ</b>: –ø–æ—á–µ–º—É —ç—Ç–æ –∑–∞–π–¥—ë—Ç –∞—É–¥–∏—Ç–æ—Ä–∏–∏

–í—ã–±–∏—Ä–∞–π —Å–∞–º–æ–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ –∏ —Ö–∞–π–ø–æ–≤–æ–µ. –ü–∏—à–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º."""

        response = self.llm.complete(
            messages=[
                Message.system("–¢—ã SMM-—ç–∫—Å–ø–µ—Ä—Ç. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –∫–æ–Ω—Ç–µ–Ω—Ç –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—à—å –∏–¥–µ–∏."),
                Message.user(prompt)
            ],
            user_id=user_id
        )

        ideas = _markdown_to_html(response.content)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–º—è—Ç—å
        self.memory.store(
            user_id=user_id,
            content=f"–ì–æ—Ä—è—á–∏–µ —Ç–µ–º—ã: {ideas[:400]}",
            memory_type=MemoryType.CONTEXT,
            importance=0.7,
            metadata={"source": "user_sources", "date": datetime.now().isoformat()}
        )

        return raw_content, ideas

    def search_for_post(self, user_id: int, query: str) -> str:
        """–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –ø–æ—Å—Ç–∞."""
        print(f"[Web] –ü–æ–∏—Å–∫: '{query}'")
        results = self.news.search_duckduckgo(query, limit=5)

        if not results:
            print(f"[Web] –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            return "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"

        print(f"[Web] –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        search_text = []
        for r in results:
            search_text.append(f"{r.title}\n{r.summary}")

        return "\n\n---\n\n".join(search_text)

    def generate_post_with_research(self, user_id: int, topic: str, style: str = None) -> PostDraft:
        """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å—Ç —Å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ–º (–≤—Å–µ–≥–¥–∞ —Å web search)."""
        print(f"[Research] –¢–µ–º–∞ —Ç—Ä–µ–±—É–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ—ã: '{topic}'")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–Ω–∞–ª –∏–∑ —Ç–µ–º—ã (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω) ‚Äî –∏—â–µ–º –∏ –ø–æ —Å–ª–æ–≤–∞–º –≤ –ø–∞–º—è—Ç–∏
        target_channel = self._extract_channel_from_topic(topic, user_id=user_id)
        smm_context = self.build_smm_context(
            user_id,
            extra_style=style or "",
            target_channel=target_channel,
            topic=topic if not target_channel else None
        )

        # –°–æ–∑–¥–∞—ë–º –∑–∞–¥–∞—á—É —Å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–º web search
        task = self.tasks.enqueue(
            user_id=user_id,
            task_type="smm_generate",
            input_text=topic,
            input_data={
                "user_id": user_id,
                "topic": topic,
                "smm_context": smm_context,
                "skip_web_search": False,  # –í—Å–µ–≥–¥–∞ –∏—Å–∫–∞—Ç—å
            }
        )

        # –ù–∞–ø—Ä—è–º—É—é –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ running
        from datetime import datetime, timezone, timedelta
        now = datetime.now(timezone.utc)
        lease_expires = now + timedelta(seconds=300)

        self.db.execute(
            """UPDATE tasks
               SET status = 'running', locked_by = ?, locked_at = ?,
                   lease_expires_at = ?, started_at = ?, updated_at = ?
               WHERE id = ?""",
            ("smm_agent", now.isoformat(), lease_expires.isoformat(),
             now.isoformat(), now.isoformat(), task.id)
        )

        draft_text = ""
        try:
            running_task = self.tasks.get_task(task.id)
            if running_task:
                self.executor.run_task(running_task)
        except ApprovalRequired as e:
            draft_text = e.draft_content or ""

        if not draft_text:
            draft_text = self._get_draft_from_task(task.id)

        return PostDraft(
            text=draft_text,
            topic=topic,
            task_id=task.id,
            channel_id=self.get_channel_id(user_id) or ""
        )

    # ==================== –†–ê–°–ü–ò–°–ê–ù–ò–ï ====================

    def get_pending_notifications(self, user_id: int) -> list:
        """–ü–æ–ª—É—á–∏—Ç—å –æ–∂–∏–¥–∞—é—â–∏–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        recent_trends = self.db.fetch_all(
            """SELECT id, content FROM memory_items
               WHERE user_id = ? AND content LIKE '–¢—Ä–µ–Ω–¥:%'
               AND created_at > datetime('now', '-1 hour')
               AND (metadata IS NULL OR metadata NOT LIKE '%"notified":true%')
               LIMIT 3""",
            (user_id,)
        )
        return recent_trends

    def mark_notified(self, memory_id: int):
        """–û—Ç–º–µ—Ç–∏—Ç—å —á—Ç–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ."""
        self.db.execute(
            "UPDATE memory_items SET metadata = json_set(COALESCE(metadata, '{}'), '$.notified', true) WHERE id = ?",
            (memory_id,)
        )

    def cleanup(self):
        """–û—á–∏—Å—Ç–∏—Ç—å —Ä–µ—Å—É—Ä—Å—ã."""
        if self._parser:
            self._parser.stop()
